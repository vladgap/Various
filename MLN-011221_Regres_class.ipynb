{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vladgap/Various/blob/main/MLN-011221_Regres_class.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWfs6xKyIiBC"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "import plotly.express as px"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VG50azfXte36"
      },
      "source": [
        "# StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jn6l3WGso4QY",
        "outputId": "c559b212-b458-44ec-f68d-2526c98a8f1d"
      },
      "source": [
        "x=[\n",
        "[2,1,0],\n",
        "[-1,0,1],\n",
        "[0,0,0],\n",
        "[1,1,0],\n",
        "[-1,-1,-1],\n",
        "[-1,1,-1],\n",
        "]\n",
        "# x=np.array(x)\n",
        "scaler = preprocessing.StandardScaler().fit(x)\n",
        "print(scaler.mean_, scaler.scale_)\n",
        "x_scaled = scaler.transform(x)\n",
        "print (x_scaled)\n",
        "x_back=scaler.inverse_transform(x_scaled)\n",
        "print (x_back)\n",
        "scaler.inverse_transform([[0,0,0]])\n",
        "# help(scaler)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.          0.33333333 -0.16666667] [1.15470054 0.74535599 0.68718427]\n",
            "[[ 1.73205081  0.89442719  0.24253563]\n",
            " [-0.8660254  -0.4472136   1.69774938]\n",
            " [ 0.         -0.4472136   0.24253563]\n",
            " [ 0.8660254   0.89442719  0.24253563]\n",
            " [-0.8660254  -1.78885438 -1.21267813]\n",
            " [-0.8660254   0.89442719 -1.21267813]]\n",
            "[[ 2.  1.  0.]\n",
            " [-1.  0.  1.]\n",
            " [ 0.  0.  0.]\n",
            " [ 1.  1.  0.]\n",
            " [-1. -1. -1.]\n",
            " [-1.  1. -1.]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.        ,  0.33333333, -0.16666667]])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUCN7lc5sieC"
      },
      "source": [
        "# Single Neuron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSEiZemKj3xT"
      },
      "source": [
        "class Neuron:\n",
        "    \"\"\"A single neuron with an activation function.\n",
        "       Attributes:\n",
        "          inputs: The number of inputs in the perceptron, not counting the bias.\n",
        "          bias:   The bias term. By defaul it's 1.0.\n",
        "          activ:  The activation function: linear (default), relu, sigmoid.\"\"\"\n",
        "\n",
        "    def __init__(self, inputs, bias = 1.0, activ = 'linear'):\n",
        "        \"\"\"Return a new Perceptron object with the specified number of inputs (+1 for the bias) and random initial weights.\"\"\" \n",
        "        self.weights = (np.random.rand(inputs+1) * 2) - 1 \n",
        "        self.bias = bias\n",
        "        self.activ = activ\n",
        "\n",
        "    def run(self, x):\n",
        "        \"\"\"Run the perceptron. x is a python list with the input values.\"\"\"\n",
        "        sum = np.dot(np.append(x,self.bias),self.weights)\n",
        "        if self.activ == 'linear':\n",
        "          return sum\n",
        "        if self.activ == 'sigmoid':\n",
        "          return self.sigmoid(sum)\n",
        "        if self.activ == 'relu':\n",
        "          return self.relu(sum)\n",
        "        if self.activ == 'mrelu':\n",
        "          return self.mrelu(sum)\n",
        "\n",
        "    def set_weights(self, w_init):\n",
        "        \"\"\"Overrides the np.random.rand() weights and the bias weight.\"\"\"\n",
        "        # w_init is a list of floats. Organize it as you'd like.\n",
        "        self.weights=np.array(w_init, dtype='double')\n",
        "\n",
        "    def set_activ(self, activ, param=0):\n",
        "        \"\"\"Overrides the 'linear' activation function.\"\"\"\n",
        "        self.activ = activ\n",
        "        self.param = param\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        # return the output of the sigmoid function applied to x\n",
        "        return 1/(1+np.exp(-x))\n",
        "    \n",
        "    def relu(self, x):\n",
        "        # return the output of the relu function applied to x\n",
        "        if x >= 0:\n",
        "          return x\n",
        "        return 0\n",
        "\n",
        "    def mrelu(self, x):\n",
        "        # return the output of the modified relu function applied to x\n",
        "        if x >= 0:\n",
        "          return x\n",
        "        return self.param*x"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nN9wRG3NlI4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e50d01e-5c3f-4bd3-d07c-c60167618b0e"
      },
      "source": [
        "neu=Neuron(inputs=2)\n",
        "neu.set_weights([10,10,-15]) \n",
        "neu.set_activ('mrelu', param=0.01)\n",
        "neu.run([1,0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.05"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bo32Xuop0eYO"
      },
      "source": [
        "## AND gate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeLvN9yxHGsw",
        "outputId": "5ea6a327-4a15-486c-eb74-5c9d5a2d9b18"
      },
      "source": [
        "neuron = Neuron(inputs=2, activ='sigmoid')\n",
        "neuron.set_weights([10,10,-15]) #AND gate\n",
        "\n",
        "print(\"AND Gate:\")\n",
        "print (\"0 0 = {0:.10f}\".format(neuron.run([0,0])))\n",
        "print (\"0 1 = {0:.10f}\".format(neuron.run([0,1])))\n",
        "print (\"1 0 = {0:.10f}\".format(neuron.run([1,0])))\n",
        "print (\"1 1 = {0:.10f}\".format(neuron.run([1,1])))\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AND Gate:\n",
            "0 0 = 0.0000003059\n",
            "0 1 = 0.0066928509\n",
            "1 0 = 0.0066928509\n",
            "1 1 = 0.9933071491\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDiUtQWL2qFC"
      },
      "source": [
        "## OR gate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJy3bJjS2qhO",
        "outputId": "8adb651f-8bd7-49eb-8b43-a71593ef80f4"
      },
      "source": [
        "neuron = Neuron(inputs=2, activ='sigmoid')\n",
        "neuron.set_weights([10,10,-5]) #OR gate\n",
        "\n",
        "print(\"OR Gate:\")\n",
        "print (\"0 0 = {0:.10f}\".format(neuron.run([0,0])))\n",
        "print (\"0 1 = {0:.10f}\".format(neuron.run([0,1])))\n",
        "print (\"1 0 = {0:.10f}\".format(neuron.run([1,0])))\n",
        "print (\"1 1 = {0:.10f}\".format(neuron.run([1,1])))\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OR Gate:\n",
            "0 0 = 0.0066928509\n",
            "0 1 = 0.9933071491\n",
            "1 0 = 0.9933071491\n",
            "1 1 = 0.9999996941\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CyK0jOA4vGH"
      },
      "source": [
        "## NAND gate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XH_wkvCq4vpB",
        "outputId": "3f2e15c7-15a8-42a0-898b-6ae7f013af96"
      },
      "source": [
        "neuron = Neuron(inputs=2, activ='sigmoid')\n",
        "neuron.set_weights([-10,-10,15]) #NAND gate\n",
        "\n",
        "print(\"NAND Gate:\")\n",
        "print (\"0 0 = {0:.10f}\".format(neuron.run([0,0])))\n",
        "print (\"0 1 = {0:.10f}\".format(neuron.run([0,1])))\n",
        "print (\"1 0 = {0:.10f}\".format(neuron.run([1,0])))\n",
        "print (\"1 1 = {0:.10f}\".format(neuron.run([1,1])))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NAND Gate:\n",
            "0 0 = 0.9999996941\n",
            "0 1 = 0.9933071491\n",
            "1 0 = 0.9933071491\n",
            "1 1 = 0.0066928509\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rpjT9eO6LeS"
      },
      "source": [
        "# Multilayer neuron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "My-snyukphuZ"
      },
      "source": [
        "class MultiLayerNeuron:     \n",
        "    \"\"\"A multilayer neuron class that uses the Neuron class above.\n",
        "       Builds a list of neurons with the specific activation function.\n",
        "       The activation function may be modified later using the set_activ method.\n",
        "       For example: mln.network[layer][neuron].set_activ('linear').\n",
        "       Attributes:\n",
        "          layers:  A list with the number of neurons per layer. Including the input (first) and the output (last) layers.\n",
        "          bias:    The bias term. The same bias is used for all neurons.\n",
        "          eta:     The learning rate.\n",
        "          activ:   The activation function: linear (default), relu, sigmoid.\"\"\"\n",
        "\n",
        "    def __init__(self, layers, bias = 1.0, eta = 0.5, activ='linear'):\n",
        "        \"\"\"Return a new MLP object with the specified parameters.\"\"\" \n",
        "        self.layers = np.array(layers,dtype=object)\n",
        "        self.bias = bias\n",
        "        self.eta = eta\n",
        "        self.network = [] # The list of lists of neurons (perceptrons).\n",
        "        self.values = []  # The list of lists of neurons' (perceptrons') output values.\n",
        "        self.d = []       # The list of lists of error terms (lowercase deltas)\n",
        "        self.activ = activ\n",
        "\n",
        "        # 2 nested loops to create neurons layer by layer\n",
        "        for i in range(len(self.layers)): # outer loop iterates on each layer\n",
        "            self.values.append([]) #The new list of values will be filled with zeros, for every neuron in the layer. \n",
        "            self.values[i] = [0.0 for j in range(self.layers[i])]\n",
        "            self.d.append([])\n",
        "            self.d[i] = [0.0 for j in range(self.layers[i])]                        \n",
        "            self.network.append([])\n",
        "            if i > 0:      #network[0] is the input layer, so it has no neurons\n",
        "                for j in range(self.layers[i]): # inner loop iterates on each neuron in a layer\n",
        "                    neur=Neuron(inputs = self.layers[i-1], bias = self.bias, activ = self.activ) # \n",
        "                    self.network[i].append(neur) # adding j perceptrons\n",
        "        \n",
        "        self.network = np.array([np.array(x) for x in self.network],dtype=object) #transforms list of lists to numpy array\n",
        "        self.values = np.array([np.array(x) for x in self.values],dtype=object)\n",
        "        self.d = np.array([np.array(x) for x in self.d],dtype=object)\n",
        "\n",
        "    def set_weights(self, w_init): # set_weights of the MultiLayer class\n",
        "        \"\"\"Set the weights. \n",
        "           w_init is a list of lists with the weights for all but the input layer.\"\"\"\n",
        "        for i in range(len(w_init)):\n",
        "            for j in range(len(w_init[i])):\n",
        "                self.network[i+1][j].set_weights(w_init[i][j]) # set_weights for each perceptron i\n",
        "\n",
        "    def set_activ(self, activ, param=0):\n",
        "        \"\"\"Set the activation function to every neurons.\"\"\"\n",
        "        for i in range(1,len(self.network)):\n",
        "            for j in range(self.layers[i]):\n",
        "                self.network[i][j].set_activ(activ, param) # set_activ for each neuron\n",
        "        self.param=param\n",
        "    \n",
        "    def set_output_activ(self, activ, param=0):\n",
        "        \"\"\"Set the activation function to the last (output) neurons.\"\"\"\n",
        "        i = len(self.network)-1\n",
        "        for j in range(self.layers[i]):\n",
        "            self.network[i][j].set_activ(activ, param) \n",
        "\n",
        "    def printWeights(self):\n",
        "        \"\"\"Displays a summary of weights and activation functions per layer and neuron.\"\"\"\n",
        "        print()\n",
        "        print('Layer 0 is the Input Layer')\n",
        "        for i in range(1,len(self.network)):\n",
        "            for j in range(self.layers[i]):\n",
        "                print(\"Layer\",i,\"Neuron\",j,\":\",self.network[i][j].weights,self.network[i][j].activ)\n",
        "        print()\n",
        "\n",
        "    def run(self, x):\n",
        "        \"\"\"Feed a sample x into the MultiLayer Neuron.\"\"\"\n",
        "        x = np.array(x,dtype=object)\n",
        "        self.values[0] = x\n",
        "        for i in range(1,len(self.network)):\n",
        "            for j in range(self.layers[i]):  \n",
        "                self.values[i][j] = self.network[i][j].run(self.values[i-1]) #runs preceptrons with the previous outputs\n",
        "        return self.values[-1]\n",
        "\n",
        "    def bp_classif(self, x, y):\n",
        "        \"\"\"Run a single (x,y) pair with the backpropagation algorithm - Gradient Descent.\n",
        "        Uses the derivative of the sigmoid function.\"\"\"\n",
        "        x = np.array(x,dtype=object)\n",
        "        y = np.array(y,dtype=object)\n",
        "        # STEP 1: Feed a sample to the network \n",
        "        outputs = self.run(x)\n",
        "        # STEP 2: Calculate the MSE\n",
        "        error = 2*(y - outputs) # A list of outputs\n",
        "        MSE = sum( error ** 2) / self.layers[-1] \n",
        "        # ∂MSE/∂weight=∂MSE/∂output*∂output/∂weight\n",
        "        # STEP 3: Calculate the OUTPUT error terms\n",
        "        # ∂MSE/∂output -- depends on neuron's activation function\n",
        "        self.d[-1] = outputs * (1 - outputs) * (error) # derivative of the SIGMOID function \n",
        "        # STEP 4: Calculate the error term of EACH UNIT on each layer\n",
        "        for i in reversed(range(1,len(self.network)-1)):\n",
        "            for h in range(len(self.network[i])):\n",
        "                fwd_error = 0.0\n",
        "                for k in range(self.layers[i+1]): \n",
        "                    fwd_error += self.network[i+1][k].weights[h] * self.d[i+1][k]               \n",
        "                self.d[i][h] = self.values[i][h] * (1-self.values[i][h]) * fwd_error # derivative of the SIGMOID function\n",
        "        # STEPS 5 & 6: Calculate the deltas and update the weights\n",
        "        for i in range(1,len(self.network)): # runs on layers\n",
        "            for j in range(self.layers[i]): # runs on neurons\n",
        "                for k in range(self.layers[i-1]+1): # runs on inputs. +1 for bias\n",
        "                    if k==self.layers[i-1]:\n",
        "                        delta = self.eta * self.d[i][j] * self.bias\n",
        "                    else:\n",
        "                        delta = self.eta * self.d[i][j] * self.values[i-1][k] # applying the delta rule\n",
        "                    self.network[i][j].weights[k] += delta\n",
        "        return MSE\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        # return the output of the sigmoid function applied to x\n",
        "        return 1/(1+np.exp(-x))\n",
        "\n",
        "    def deriv(self, value, i, j=0):\n",
        "        if self.network[i][j].activ == 'linear':\n",
        "          # print ('lin')\n",
        "          return 1\n",
        "        if self.network[i][j].activ == 'sigmoid':\n",
        "          # print ('sig')\n",
        "          return self.sigmoid(value)*(1-self.sigmoid(value))\n",
        "        if self.network[i][j].activ == 'relu':\n",
        "          if value > 0:\n",
        "            # print ('re>')\n",
        "            return 1\n",
        "          else:\n",
        "            # print ('re<')\n",
        "            return 0\n",
        "        if self.network[i][j].activ == 'mrelu':\n",
        "          if value > 0:\n",
        "            return 1\n",
        "          else:\n",
        "            return self.param\n",
        "\n",
        "    def bp_regres(self, x, y):\n",
        "        \"\"\"Run a single (x,y) pair with the backpropagation algorithm - Gradient Descent.\n",
        "        Uses the derivative according each neuron's activation function.\"\"\"\n",
        "        x = np.array(x,dtype=object)\n",
        "        y = np.array(y,dtype=object)\n",
        "        # STEP 1: Feed a sample to the network \n",
        "        outputs = self.run(x)\n",
        "        # STEP 2: Calculate the MSE\n",
        "        error = 2*(y - outputs) # A list of outputs\n",
        "        MSE = sum( error ** 2) / self.layers[-1] \n",
        "        # ∂MSE/∂weight=∂MSE/∂output*∂output/∂weight\n",
        "        # STEP 3: Calculate the OUTPUT error terms\n",
        "        # ∂MSE/∂output -- depends on neuron's activation function\n",
        "        for j in range (len(outputs)):\n",
        "            self.d[-1][j] = self.deriv(outputs[j], len(self.network)-1) * error\n",
        "        # STEP 4: Calculate the error term of EACH UNIT on each layer\n",
        "        for i in reversed(range(1,len(self.network)-1)):\n",
        "            for h in range(len(self.network[i])):\n",
        "                fwd_error = 0.0\n",
        "                for k in range(self.layers[i+1]): \n",
        "                    fwd_error += self.network[i+1][k].weights[h] * self.d[i+1][k] \n",
        "                self.d[i][h] = self.deriv(self.values[i][h], i, h) * fwd_error\n",
        "        # STEPS 5 & 6: Calculate the deltas and update the weights\n",
        "        for i in range(1,len(self.network)): # runs on layers\n",
        "            for j in range(self.layers[i]): # runs on neurons\n",
        "                for k in range(self.layers[i-1]+1): # runs on inputs. +1 for bias\n",
        "                    # output=sum(weight*value)+bias*bias_weight\n",
        "                    if k==self.layers[i-1]:\n",
        "                        # ∂output/∂bias_weight=bias\n",
        "                        delta = self.eta * self.d[i][j] * self.bias\n",
        "                    else:\n",
        "                        # ∂output/∂weight=value\n",
        "                        delta = self.eta * self.d[i][j] * self.values[i-1][k] \n",
        "                    self.network[i][j].weights[k] += delta # applying the delta rule\n",
        "        return MSE"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlSin4uPzSFX"
      },
      "source": [
        "## XOR gate=(OR+NAND)+AND"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2dcROXuqJT1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8335e7c8-fea9-419b-ae2b-0dbc670ac98d"
      },
      "source": [
        "#test code\n",
        "mln1 = MultiLayerNeuron(layers=[2,2,1])  #mln1\n",
        "mln1.set_weights([[[-10,-10,15],[15,15,-10]],[[10,10,-15]]])\n",
        "mln1.set_activ('sigmoid') #linear is by default\n",
        "\n",
        "mln1.printWeights()\n",
        "print(\"XOR Gate:\")\n",
        "print (\"0 0 = {0:.10f}\".format(mln1.run([0,0])[0]))\n",
        "print (\"0 1 = {0:.10f}\".format(mln1.run([0,1])[0]))\n",
        "print (\"1 0 = {0:.10f}\".format(mln1.run([1,0])[0]))\n",
        "print (\"1 1 = {0:.10f}\".format(mln1.run([1,1])[0]))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Layer 0 is the Input Layer\n",
            "Layer 1 Neuron 0 : [-10. -10.  15.] sigmoid\n",
            "Layer 1 Neuron 1 : [ 15.  15. -10.] sigmoid\n",
            "Layer 2 Neuron 0 : [ 10.  10. -15.] sigmoid\n",
            "\n",
            "XOR Gate:\n",
            "0 0 = 0.0066958493\n",
            "0 1 = 0.9923558642\n",
            "1 0 = 0.9923558642\n",
            "1 1 = 0.0071528098\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBf5fifWK_EG"
      },
      "source": [
        "## Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaZYikTxNp69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0aba99a9-669a-45d2-f0a6-83fcbdb3b5fe"
      },
      "source": [
        "mln2 = MultiLayerNeuron(layers=[2,2,1])\n",
        "mln2.set_activ('sigmoid') #linear is by default\n",
        "print(\"\\nTraining Neural Network as an XOR Gate...\\n\")\n",
        "for i in range(2000):\n",
        "    MSE = 0.0\n",
        "    MSE += mln2.bp_classif([0,0],[0])\n",
        "    MSE += mln2.bp_classif([0,1],[1])\n",
        "    MSE += mln2.bp_classif([1,0],[1])\n",
        "    MSE += mln2.bp_classif([1,1],[0])\n",
        "    MSE = MSE / 4\n",
        "    if(i%200 == 0):\n",
        "        print (MSE)\n",
        "\n",
        "mln2.printWeights()\n",
        "    \n",
        "print(\"XOR Gate:\")\n",
        "print (\"0 0 = {0:.10f}\".format(mln2.run([0,0])[0]))\n",
        "print (\"0 1 = {0:.10f}\".format(mln2.run([0,1])[0]))\n",
        "print (\"1 0 = {0:.10f}\".format(mln2.run([1,0])[0]))\n",
        "print (\"1 1 = {0:.10f}\".format(mln2.run([1,1])[0]))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Neural Network as an XOR Gate...\n",
            "\n",
            "1.3668306600311346\n",
            "0.9091274518948705\n",
            "0.06749272897836474\n",
            "0.022475612733651288\n",
            "0.012867627612127681\n",
            "0.008881300026390527\n",
            "0.006734169633314301\n",
            "0.005402332555512186\n",
            "0.004499546039950102\n",
            "0.0038490963301811352\n",
            "\n",
            "Layer 0 is the Input Layer\n",
            "Layer 1 Neuron 0 : [-5.87291793  5.72395499 -3.21515389] sigmoid\n",
            "Layer 1 Neuron 1 : [ 5.33018183 -5.55891598 -2.97863353] sigmoid\n",
            "Layer 2 Neuron 0 : [ 8.33464253  8.42415784 -4.13709532] sigmoid\n",
            "\n",
            "XOR Gate:\n",
            "0 0 = 0.0320572595\n",
            "0 1 = 0.9726702741\n",
            "1 0 = 0.9722286081\n",
            "1 1 = 0.0284482357\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZS1-UADpTpY"
      },
      "source": [
        "# Regres"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkOQ9tbuvI9P"
      },
      "source": [
        "class Regres:\n",
        "    def __init__(self, layers, bias=1.0, eta=0.1, ):\n",
        "        self.layers = layers\n",
        "        self.bias = bias\n",
        "        self.eta = eta\n",
        "        self.regres_network = MultiLayerNeuron(layers=layers, bias=bias, eta=eta)\n",
        "\n",
        "    def set_weights(self, w_init):\n",
        "        self.regres_network.set_weights(w_init)\n",
        "\n",
        "    def set_hidden_activ(self, activ, param=0):\n",
        "        self.regres_network.set_activ(activ, param=0)\n",
        "        self.regres_network.set_output_activ('linear')\n",
        "\n",
        "    def fit(self, X, y, epochs):\n",
        "        self.epochs=epochs\n",
        "        self.weight_history=[]\n",
        "        self.weight_history_table=[]\n",
        "        # self.cols=[]\n",
        "        self.MSE_history=[]\n",
        "        for i in range(self.epochs):\n",
        "            weight_epoch=[]\n",
        "            weight_epoch_table=[]\n",
        "            MSE = 0.0\n",
        "            for j in range (len(X)):\n",
        "                MSE +=  self.regres_network.bp_regres(X[j],[y[j]])\n",
        "            MSE = MSE / len(X)\n",
        "            self.MSE_history.append(MSE)\n",
        "            for m in range(1,len(self.layers)):\n",
        "                for n in range(self.layers[m]):\n",
        "                    # col=\"{}_{}\".format(m,n)\n",
        "                    # self.cols.append(col)\n",
        "                    neuron_w=self.regres_network.network[m][n].weights\n",
        "                    neuron_w_list=[x for x in neuron_w]\n",
        "                    weight_epoch.append(neuron_w_list)\n",
        "                    weight_epoch_table+=neuron_w_list\n",
        "            self.weight_history.append(weight_epoch)\n",
        "            self.weight_history_table.append(weight_epoch_table)\n",
        "        self.weight_history_table=pd.DataFrame(data=self.weight_history_table, columns=self.get_cols())\n",
        "        print (\"\"\"Model fitted.\n",
        "self.weight_history - list of lists of weights propagation\n",
        "self.weight_history_table - pandas table of weights propagation\n",
        "self.MSE_history - list of MSEs propagation\"\"\")\n",
        "\n",
        "    def get_cols(self): \n",
        "        cols=[]\n",
        "        for i in range(1,len(self.layers)):\n",
        "            for h in range(self.layers[i]):\n",
        "                for k in range(self.layers[i-1]+1): \n",
        "                    col=\"{}_{}_{}\".format(i,h,k) \n",
        "                    cols.append(col)\n",
        "        return cols \n",
        "    \n",
        "    def printWeights(self):\n",
        "        self.regres_network.printWeights()\n",
        "\n",
        "    def run(self, x):\n",
        "        return self.regres_network.run(x)\n",
        "\n",
        "    def predict(self, x):\n",
        "        y=[]\n",
        "        for i in range(len(x)):\n",
        "            y.append(self.run(x[i])[0])\n",
        "        return y"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rarzZ-VuIoF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2502275d-d404-48c0-a0fc-b7b3f3226085"
      },
      "source": [
        "weight_history=[]\n",
        "a=[[1,2],[1,3],[4,1]]\n",
        "b=[]\n",
        "for m in range(3):\n",
        "  for n in range(2):\n",
        "    b.append(a[m][n])\n",
        "print (\"b\",b)\n",
        "weight_history.append(b)\n",
        "print (weight_history)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b [1, 2, 1, 3, 4, 1]\n",
            "[[1, 2, 1, 3, 4, 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqJ8FTGSvCrP"
      },
      "source": [
        "# Regres_scale"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zz-y1CtyyZvy"
      },
      "source": [
        "# nuzhno podumat' kak vesa obratno perevesti. mozhet inverse_transform\n",
        "class Regres_scale:\n",
        "    def __init__(self, layers, bias=1.0, eta=0.5, ):\n",
        "        self.layers = layers\n",
        "        self.bias = bias\n",
        "        self.eta = eta\n",
        "        # self.epochs = epochs      \n",
        "        self.regres_network = MultiLayerNeuron(layers=layers, bias=bias, eta=eta)\n",
        "\n",
        "    def set_weights(self, w_init):\n",
        "        self.regres_network.set_weights(w_init)\n",
        "\n",
        "    def set_hidden_activ(self, activ):\n",
        "        self.regres_network.set_activ(activ)\n",
        "        self.regres_network.set_output_activ('linear')\n",
        "\n",
        "    def fit(self, x, y, epochs):\n",
        "        self.scaler = preprocessing.StandardScaler().fit(x)\n",
        "        x_scaled=self.scaler.transform(x)\n",
        "        self.epochs=epochs\n",
        "        for i in range(epochs):\n",
        "            MSE = 0.0\n",
        "            for j in range (len(x)):\n",
        "                MSE +=  self.regres_network.bp_regres(x_scaled[j],[y[j]])\n",
        "            MSE = MSE / len(x)\n",
        "            # dobavit' istoriyu kak v Regres\n",
        "\n",
        "    def printWeights(self):\n",
        "        self.regres_network.printWeights()\n",
        "\n",
        "    def run(self, x):\n",
        "        return self.regres_network.run(x)\n",
        "\n",
        "    def predict(self, x):\n",
        "        y=[]\n",
        "        for i in range(len(x)):\n",
        "            y.append(self.run(x[i])[0])\n",
        "        return y\n",
        "\n",
        "    def get_standard_params(self, x):\n",
        "        x2=np.array(x)\n",
        "        mean=x2.mean(axis=0)\n",
        "        stdev=x2.std(axis=0)\n",
        "        return mean, stdev"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1CIr02vJjVL"
      },
      "source": [
        "# Example 1 -- weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1cXJqv6KPD9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab9a4824-2e36-4b67-b69a-927500d2d241"
      },
      "source": [
        "print (\"1 1 =\",mln1.run([1,1]))\n",
        "# print (mln1.network[1][0].weights) # network is list of lists of perceptrons. Each has attribute \"weights\"\n",
        "w1=mln1.network[1][0].weights\n",
        "w2=[x for x in w1]\n",
        "w2"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 1 = [0.42896503]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-0.4935207493697864, 0.3834408303278405, -0.03511010044167673]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mV8ZGDKCGdig",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cf8228f-5bf6-48ff-9bc5-74c5bdd0087b"
      },
      "source": [
        "mln1=MultiLayerNeuron(layers=[2,2,1])\n",
        "mln1.set_activ('relu')\n",
        "mln1.printWeights()\n",
        "\n",
        "mln1.set_output_activ('sigmoid') # setting the output activ func\n",
        "mln1.printWeights()\n",
        "\n",
        "mln1.network[1][0].set_activ('linear') # changing specific activ func\n",
        "mln1.printWeights()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Layer 0 is the Input Layer\n",
            "Layer 1 Neuron 0 : [-0.49352075  0.38344083 -0.0351101 ] relu\n",
            "Layer 1 Neuron 1 : [0.0157239  0.32777417 0.77556509] relu\n",
            "Layer 2 Neuron 0 : [-0.15919856  0.39479284 -0.75098722] relu\n",
            "\n",
            "\n",
            "Layer 0 is the Input Layer\n",
            "Layer 1 Neuron 0 : [-0.49352075  0.38344083 -0.0351101 ] relu\n",
            "Layer 1 Neuron 1 : [0.0157239  0.32777417 0.77556509] relu\n",
            "Layer 2 Neuron 0 : [-0.15919856  0.39479284 -0.75098722] sigmoid\n",
            "\n",
            "\n",
            "Layer 0 is the Input Layer\n",
            "Layer 1 Neuron 0 : [-0.49352075  0.38344083 -0.0351101 ] linear\n",
            "Layer 1 Neuron 1 : [0.0157239  0.32777417 0.77556509] relu\n",
            "Layer 2 Neuron 0 : [-0.15919856  0.39479284 -0.75098722] sigmoid\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFSdNaYSKr7h"
      },
      "source": [
        "# Example 3 -- linear activs, bp_regres. מתכנס למשקלים טוב מאוד "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsu-mr5IdZlt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "692f6a8b-c68f-49f1-9d09-f7670dceafa6"
      },
      "source": [
        "mln3 = MultiLayerNeuron(layers=[3,1], eta=0.3)\n",
        "# mln3.set_weights([[[5.,-0.9,2.,0.]]])\n",
        "mln3.set_weights([[[0,0,0,0]]])\n",
        "mln3.printWeights()\n",
        "print(\"\\nTraining Neural Network...\\n\")\n",
        "for i in range(400):\n",
        "    MSE = 0.0\n",
        "    MSE += mln3.bp_regres([0.7759,\t0.1104,\t0.9977,],5.764286995)\n",
        "    MSE += mln3.bp_regres([0.9692,\t0.6961,\t0.8483,],5.84646758)\n",
        "    MSE += mln3.bp_regres([0.0265,\t0.399,\t0.5375,],0.808633075)\n",
        "    MSE += mln3.bp_regres([0.7694,\t0.5051,\t0.2542,],3.850298589)\n",
        "    MSE = MSE / 4\n",
        "    if(i%200 == 0):\n",
        "        print (MSE)\n",
        "\n",
        "mln3.printWeights()\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Layer 0 is the Input Layer\n",
            "Layer 1 Neuron 0 : [0. 0. 0. 0.] linear\n",
            "\n",
            "\n",
            "Training Neural Network...\n",
            "\n",
            "54.560573414122615\n",
            "9.652321993077698e-13\n",
            "\n",
            "Layer 0 is the Input Layer\n",
            "Layer 1 Neuron 0 : [ 4.99973369e+00 -9.99625006e-01  1.99991681e+00  3.52253294e-05] linear\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwlXhDA2KORl"
      },
      "source": [
        "# Example 4 -- sigmoid, bp_regres. מקרב רגרסיה עם סיגמויד. עובד טוב"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBA-VYuEJGm2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657
        },
        "outputId": "bd8b0647-d99d-410a-b679-f7ac50245f4e"
      },
      "source": [
        "# generating output values\n",
        "mln4 = MultiLayerNeuron(layers=[3,2,1])\n",
        "mln4.set_activ('sigmoid')\n",
        "mln4.set_output_activ('linear')\n",
        "mln4.set_weights([[[0,1,-2,1],[1,-2,0,1]],[[-1,2,3]]])\n",
        "mln4.printWeights()\n",
        "\n",
        "y4=[]\n",
        "y4.append(mln4.run([2,1,0])[0])\n",
        "y4.append(mln4.run([-1,0,1])[0])\n",
        "y4.append(mln4.run([0,0,0])[0])\n",
        "y4.append(mln4.run([1,1,0])[0])\n",
        "y4.append(mln4.run([-1,-1,-1])[0])\n",
        "y4.append(mln4.run([-1,1,-1])[0])\n",
        "display ('original values:',y4)\n",
        "print ()\n",
        "\n",
        "# training model and predicting values\n",
        "mln4 = MultiLayerNeuron(layers=[3,2,1], eta=0.1)\n",
        "mln4.set_activ('sigmoid')\n",
        "mln4.set_output_activ('linear')\n",
        "\n",
        "for i in range(1000):\n",
        "    MSE = 0.0\n",
        "    MSE += mln4.bp_regres([2,1,0],y4[0])\n",
        "    MSE += mln4.bp_regres([-1,0,1],y4[1])\n",
        "    MSE += mln4.bp_regres([0,0,0],y4[2])\n",
        "    MSE += mln4.bp_regres([1,1,0],y4[3])\n",
        "    MSE += mln4.bp_regres([-1,-1,-1],y4[4])\n",
        "    MSE += mln4.bp_regres([-1,1,-1],y4[5])\n",
        "    MSE = MSE / 6\n",
        "    if(i%200 == 0):\n",
        "        print ('MSE=',MSE)\n",
        "mln4.printWeights()\n",
        "\n",
        "y4=[]\n",
        "y4.append(mln4.run([2,1,0])[0])\n",
        "y4.append(mln4.run([-1,0,1])[0])\n",
        "y4.append(mln4.run([0,0,0])[0])\n",
        "y4.append(mln4.run([1,1,0])[0])\n",
        "y4.append(mln4.run([-1,-1,-1])[0])\n",
        "y4.append(mln4.run([-1,1,-1])[0])\n",
        "display ('predicted values:',y4)\n",
        "print ()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Layer 0 is the Input Layer\n",
            "Layer 1 Neuron 0 : [ 0.  1. -2.  1.] sigmoid\n",
            "Layer 1 Neuron 1 : [ 1. -2.  0.  1.] sigmoid\n",
            "Layer 2 Neuron 0 : [-1.  2.  3.] linear\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'original values:'"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[3.5813200792821274,\n",
              " 3.731058578630005,\n",
              " 3.731058578630005,\n",
              " 3.119202922022118,\n",
              " 3.880797077977882,\n",
              " 2.2563920540063265]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "MSE= 19.489652799555873\n",
            "MSE= 0.02728719311677784\n",
            "MSE= 0.02113912897034817\n",
            "MSE= 0.017195069423565287\n",
            "MSE= 0.014455978355482063\n",
            "\n",
            "Layer 0 is the Input Layer\n",
            "Layer 1 Neuron 0 : [ 0.42308272 -0.99135748  0.60655673  1.21673559] sigmoid\n",
            "Layer 1 Neuron 1 : [ 0.39791135 -1.1013564   0.27332004 -0.02605244] sigmoid\n",
            "Layer 2 Neuron 0 : [1.66063715 1.95626123 1.45068755] linear\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'predicted values:'"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[3.505113170657939,\n",
              " 3.687474139534376,\n",
              " 3.697240113477619,\n",
              " 3.177548988410871,\n",
              " 3.893629219455489,\n",
              " 2.2418366346641716]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQ6f38VkOng4"
      },
      "source": [
        "# Example 5 -- relu-sigmoid, bp_regres. מתכנס למשקלים לא משהו"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTgRMD9GOoF_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        },
        "outputId": "8d5ad0d9-9d93-45a5-fa3d-93adf56f4d27"
      },
      "source": [
        "mln4 = MultiLayerNeuron(layers=[3,2,1,1]) # generating MLN with random weights\n",
        "mln4.set_activ('relu')\n",
        "mln4.network[2][0].set_activ('sigmoid') # changing specific activ func\n",
        "mln4.set_output_activ('linear')\n",
        "mln4.set_weights([[[0,1,-2,1],[1,-2,0,1]],[[1,0,1]],[[-1,2]]]) # setting weights\n",
        "mln4.printWeights()\n",
        "\n",
        "y4=[] # generating output values\n",
        "y4.append(mln4.run([2,1,0])[0])\n",
        "y4.append(mln4.run([-1,0,1])[0])\n",
        "y4.append(mln4.run([0,0,0])[0])\n",
        "y4.append(mln4.run([1,1,0])[0])\n",
        "y4.append(mln4.run([-1,-1,-1])[0])\n",
        "y4.append(mln4.run([-1,1,-1])[0])\n",
        "display ('original values:',y4)\n",
        "print ()\n",
        "\n",
        "# training model and predicting values\n",
        "mln4 = MultiLayerNeuron(layers=[3,2,1,1], eta=0.3) # generating MLN with random weights\n",
        "mln4.set_activ('relu')\n",
        "mln4.network[2][0].set_activ('sigmoid') # changing specific activ func\n",
        "mln4.set_output_activ('linear')\n",
        "\n",
        "for i in range(400):\n",
        "    MSE = 0.0\n",
        "    MSE += mln4.bp_regres([2,1,0],y4[0])\n",
        "    MSE += mln4.bp_regres([-1,0,1],y4[1])\n",
        "    MSE += mln4.bp_regres([0,0,0],y4[2])\n",
        "    MSE += mln4.bp_regres([1,1,0],y4[3])\n",
        "    MSE += mln4.bp_regres([-1,-1,-1],y4[4])\n",
        "    MSE += mln4.bp_regres([-1,1,-1],y4[5])\n",
        "    MSE = MSE / 6\n",
        "    if(i%20 == 0):\n",
        "        print ('MSE', i, '=',MSE)\n",
        "mln4.printWeights()\n",
        "\n",
        "y4=[]\n",
        "y4.append(mln4.run([2,1,0])[0])\n",
        "y4.append(mln4.run([-1,0,1])[0])\n",
        "y4.append(mln4.run([0,0,0])[0])\n",
        "y4.append(mln4.run([1,1,0])[0])\n",
        "y4.append(mln4.run([-1,-1,-1])[0])\n",
        "y4.append(mln4.run([-1,1,-1])[0])\n",
        "display ('predicted values:',y4)\n",
        "print ()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Layer 0 is the Input Layer\n",
            "Layer 1 Neuron 0 : [ 0.  1. -2.  1.] relu\n",
            "Layer 1 Neuron 1 : [ 1. -2.  0.  1.] relu\n",
            "Layer 2 Neuron 0 : [1. 0. 1.] sigmoid\n",
            "Layer 3 Neuron 0 : [-1.  2.] linear\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'original values:'"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1.0474258731775667,\n",
              " 1.2689414213699952,\n",
              " 1.1192029220221178,\n",
              " 1.0474258731775667,\n",
              " 1.0474258731775667,\n",
              " 1.0066928509242847]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "MSE 0 = 1.2428698204664617\n",
            "MSE 20 = 0.05337800911055901\n",
            "MSE 40 = 0.042515350384664745\n",
            "MSE 60 = 0.013704007731044401\n",
            "MSE 80 = 0.00824950743488877\n",
            "MSE 100 = 0.00880943721040711\n",
            "MSE 120 = 0.008852923971947977\n",
            "MSE 140 = 0.008888057472520682\n",
            "MSE 160 = 0.008904751383209933\n",
            "MSE 180 = 0.008912233949436668\n",
            "MSE 200 = 0.00891486296949455\n",
            "MSE 220 = 0.008914943843271107\n",
            "MSE 240 = 0.008913691399401897\n",
            "MSE 260 = 0.00891174076377044\n",
            "MSE 280 = 0.008909422512809767\n",
            "MSE 300 = 0.008906908337551027\n",
            "MSE 320 = 0.00890428733363357\n",
            "MSE 340 = 0.008901605735332434\n",
            "MSE 360 = 0.00887551691173158\n",
            "MSE 380 = 0.008884061075500903\n",
            "\n",
            "Layer 0 is the Input Layer\n",
            "Layer 1 Neuron 0 : [ 0.28731933 -0.62145969  0.28064334 -0.00380912] relu\n",
            "Layer 1 Neuron 1 : [-0.25430956  0.5153527   1.31925083 -0.26112722] relu\n",
            "Layer 2 Neuron 0 : [-0.34021665  0.57002803  0.50218212] sigmoid\n",
            "Layer 3 Neuron 0 : [1.44922792 0.10840802] linear\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'predicted values:'"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1.0112364383024495,\n",
              " 1.2349693951440601,\n",
              " 1.0112364383024495,\n",
              " 1.0112364383024495,\n",
              " 1.0054703877519875,\n",
              " 1.0112364383024495]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iig6wESsnxe"
      },
      "source": [
        "# Example 7 -- Regres class. עובד באופן עקרוני\n",
        "# relu בעייתי"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6k1A-gflH4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5e1efa8-674c-4162-e40e-eae07c3444aa"
      },
      "source": [
        "reg1=Regres(layers=[3,2,1,1], eta=0.3)\n",
        "reg1.set_weights([[[1,1,0,0],[0,0,0,0]],[[0,0,0]],[[0,0]]])\n",
        "X=[\n",
        "[2,1,0],\n",
        "[-1,0,1],\n",
        "[0,0,0],\n",
        "[1,1,0],\n",
        "[-1,-1,-1],\n",
        "[-1,1,-1],\n",
        "]\n",
        "y=[1.0474258731775667,\n",
        " 1.2689414213699952,\n",
        " 1.1192029220221178,\n",
        " 1.0474258731775667,\n",
        " 1.0474258731775667,\n",
        " 1.0066928509242847]\n",
        "reg1.set_hidden_activ('relu')\n",
        "reg1.regres_network.network[2][0].set_activ('sigmoid') # changing specific activ func\n",
        "reg1.fit(X,y, epochs=5)\n",
        "reg1.printWeights()\n",
        "pred=reg1.predict(X)\n",
        "print (pred)\n",
        "print()\n",
        "# display ('weight_history',reg1.weight_history)\n",
        "display ('MSE',reg1.MSE_history)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weight_epoch [array([1., 1., 0., 0.]), array([0., 0., 0., 0.]), array([-0.01004363,  0.        ,  0.01054202]), array([0.40626752, 0.81345965])]\n",
            "weight_epoch [array([ 9.99943510e-01,  1.00005251e+00, -4.50468799e-05,  5.25099344e-05]), array([0., 0., 0., 0.]), array([-0.01639217,  0.        ,  0.00904985]), array([0.40618406, 0.81392458])]\n",
            "weight_epoch [array([ 9.99878829e-01,  1.00014354e+00, -1.06675990e-04,  2.11560284e-04]), array([0., 0., 0., 0.]), array([-0.02228857,  0.        ,  0.00755239]), array([0.4060741 , 0.81421285])]\n",
            "weight_epoch [array([ 9.99802753e-01,  1.00026810e+00, -1.83813904e-04,  4.40823369e-04]), array([0., 0., 0., 0.]), array([-0.02773872,  0.        ,  0.00606316]), array([0.405996  , 0.81447959])]\n",
            "weight_epoch [array([ 9.99713140e-01,  1.00042202e+00, -2.75446741e-04,  7.33518678e-04]), array([0., 0., 0., 0.]), array([-0.03277788,  0.        ,  0.00458208]), array([0.40593827, 0.81473119])]\n",
            "Model fitted.\n",
            "self.weight_history - list of lists of weights propagation\n",
            "self.MSE_history - list of MSEs propagation\n",
            "\n",
            "Layer 0 is the Input Layer\n",
            "Layer 1 Neuron 0 : [ 9.99713140e-01  1.00042202e+00 -2.75446741e-04  7.33518678e-04] relu\n",
            "Layer 1 Neuron 1 : [0. 0. 0. 0.] relu\n",
            "Layer 2 Neuron 0 : [-0.03277788  0.          0.00458208] sigmoid\n",
            "Layer 3 Neuron 0 : [0.40593827 0.81473119] linear\n",
            "\n",
            "[1.0081910251075497, 1.0181653384338307, 1.0181628984344357, 1.0115114716378777, 1.0181653384338307, 1.0181596241520412]\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'MSE'"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[0.8936248829442258,\n",
              " 0.04857883327236249,\n",
              " 0.0481469881158581,\n",
              " 0.04777680393002976,\n",
              " 0.04744442311981101]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bxt-T9Qs5zv"
      },
      "source": [
        "# Example -- Regres_scale. צריך חשוב ולהשלים"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0_dFIMLvjG9",
        "outputId": "4e279eb7-768f-45d6-f5b2-c2868ff8c566"
      },
      "source": [
        "# nuzhno podumat' kak vesa obratno perevesti. mozhet inverse_transform\n",
        "reg2=Regres_scale(layers=[3,2,1,1], eta=0.1)\n",
        "reg2.set_weights([[[1,1,0,0],[0,0,0,0]],[[0,0,0]],[[0,0]]])\n",
        "X=[\n",
        "[2,1,0],\n",
        "[-1,0,1],\n",
        "[0,0,0],\n",
        "[1,1,0],\n",
        "[-1,-1,-1],\n",
        "[-1,1,-1],\n",
        "]\n",
        "y=[1.0474258731775667,\n",
        " 1.2689414213699952,\n",
        " 1.1192029220221178,\n",
        " 1.0474258731775667,\n",
        " 1.0474258731775667,\n",
        " 1.0066928509242847]\n",
        "reg2.set_hidden_activ('relu')\n",
        "reg2.regres_network.network[2][0].set_activ('sigmoid') # changing specific activ func\n",
        "reg2.fit(X,y,epochs=200)\n",
        "reg2.printWeights()\n",
        "pred=reg2.predict(X)\n",
        "pred"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Layer 0 is the Input Layer\n",
            "Layer 1 Neuron 0 : [ 0.9517462   1.06201428 -0.06407585  0.06933407] relu\n",
            "Layer 1 Neuron 1 : [0. 0. 0. 0.] relu\n",
            "Layer 2 Neuron 0 : [-0.20894407  0.          0.00917428] sigmoid\n",
            "Layer 3 Neuron 0 : [0.46600036 0.84566849] linear\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0081438427807037,\n",
              " 1.0797374688505368,\n",
              " 1.078049747612554,\n",
              " 1.029768336904302,\n",
              " 1.0797374688505368,\n",
              " 1.073806571646052]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMQEsh7bFFe9"
      },
      "source": [
        "# Example 6 -- https://mmuratarat.github.io/2020-01-09/backpropagation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvAnY1Q1FF_L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d039b0e-d459-484e-d110-9eba7067fd91"
      },
      "source": [
        "# generating output values\n",
        "mln6 = MultiLayerNeuron(layers=[5,3,1], eta=.5)\n",
        "mln6.set_activ('sigmoid')\n",
        "mln6.set_output_activ('linear')\n",
        "mln6.set_weights([[[.19,.33,.4,.51,.54,.1],\n",
        "                   [.55,.16,.35,.85,.49,.1],\n",
        "                   [.76,.97,.7,.85,.57,.1]],\n",
        "                  [[.1,.03,-.17,.1]]\n",
        "                  ]) # setting initial weights\n",
        "mln6.printWeights()\n",
        "\n",
        "# training\n",
        "for i in range(100):\n",
        "    MSE = 0.0\n",
        "    MSE += mln6.bp_regres([.5,.1,1,0,0],[0.1])\n",
        "    MSE += mln6.bp_regres([.3,.2,0,1,0],[.6])\n",
        "    MSE += mln6.bp_regres([.7,.9,0,0,1],[.4])\n",
        "    MSE += mln6.bp_regres([.8,.1,1,0,0],[.1])\n",
        "    MSE = MSE / 4\n",
        "    if(i%10 == 0):\n",
        "        print ('MSE', i, '=',MSE)\n",
        "\n",
        "mln6.printWeights()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Layer 0 is the Input Layer\n",
            "Layer 1 Neuron 0 : [0.19 0.33 0.4  0.51 0.54 0.1 ] sigmoid\n",
            "Layer 1 Neuron 1 : [0.55 0.16 0.35 0.85 0.49 0.1 ] sigmoid\n",
            "Layer 1 Neuron 2 : [0.76 0.97 0.7  0.85 0.57 0.1 ] sigmoid\n",
            "Layer 2 Neuron 0 : [ 0.1   0.03 -0.17  0.1 ] linear\n",
            "\n",
            "MSE 0 = 3.097759865123268\n",
            "MSE 10 = 0.2948017967667316\n",
            "MSE 20 = 0.11235016703947856\n",
            "MSE 30 = 0.039031749833149484\n",
            "MSE 40 = 0.005346702764168406\n",
            "MSE 50 = 0.00047155150910413527\n",
            "MSE 60 = 9.822149422722454e-05\n",
            "MSE 70 = 6.0504726410544755e-05\n",
            "MSE 80 = 4.67746394940529e-05\n",
            "MSE 90 = 3.966114337742912e-05\n",
            "\n",
            "Layer 0 is the Input Layer\n",
            "Layer 1 Neuron 0 : [-0.92948745 -0.3432972  -0.4785581   0.21811547 -0.0456272  -1.65606983] sigmoid\n",
            "Layer 1 Neuron 1 : [-1.01311017 -0.23274925 -1.57166574  1.18384536  0.1929425  -1.78487787] sigmoid\n",
            "Layer 1 Neuron 2 : [-0.09277171 -0.3986799   1.19699659 -0.59778185 -0.68424799 -2.10503325] sigmoid\n",
            "Layer 2 Neuron 0 : [ 0.25752661  0.97942477 -1.06640139  0.35525422] linear\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhdtW0Cjc7Fi"
      },
      "source": [
        "# Example 8 -- Relu check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eWXM7kbc6gn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 672
        },
        "outputId": "183b48d9-9c4b-4407-8403-ac5abd73e96b"
      },
      "source": [
        "reg2=Regres(layers=[1,2,1], eta=0.01)\n",
        "X=[[0],[1],[2],[3],[4],[5]]\n",
        "y=[0,1,2,3,4,5]\n",
        "reg2.printWeights()\n",
        "\n",
        "reg2.set_hidden_activ('linear')\n",
        "reg2.fit(X,y,epochs=5)\n",
        "reg2.printWeights()\n",
        "pred=reg2.predict(X)\n",
        "print ('predictions',pred)\n",
        "display ('weight_history_table',reg2.weight_history_table)\n",
        "display ('MSE',reg2.MSE_history)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Layer 0 is the Input Layer\n",
            "Layer 1 Neuron 0 : [-0.01131819  0.5324673 ] linear\n",
            "Layer 1 Neuron 1 : [0.72387826 0.10673647] linear\n",
            "Layer 2 Neuron 0 : [-0.81721239 -0.05371982  0.22557585] linear\n",
            "\n",
            "Model fitted.\n",
            "self.weight_history - list of lists of weights propagation\n",
            "self.weight_history_table - pandas table of weights propagation\n",
            "self.MSE_history - list of MSEs propagation\n",
            "\n",
            "Layer 0 is the Input Layer\n",
            "Layer 1 Neuron 0 : [-0.59726066  0.37106217] linear\n",
            "Layer 1 Neuron 1 : [0.84543639 0.1187419 ] linear\n",
            "Layer 2 Neuron 0 : [-0.89429205  0.51401691  0.43162184] linear\n",
            "\n",
            "predictions [0.16081923708480456, 1.1295132920519806, 2.098207347019157, 3.066901401986333, 4.0355954569535095, 5.004289511920685]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'weight_history_table'"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1_0_0</th>\n",
              "      <th>1_0_1</th>\n",
              "      <th>1_1_0</th>\n",
              "      <th>1_1_1</th>\n",
              "      <th>2_0_0</th>\n",
              "      <th>2_0_1</th>\n",
              "      <th>2_0_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.563676</td>\n",
              "      <td>0.355707</td>\n",
              "      <td>0.826498</td>\n",
              "      <td>0.127656</td>\n",
              "      <td>-0.866058</td>\n",
              "      <td>0.484198</td>\n",
              "      <td>0.448856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.594539</td>\n",
              "      <td>0.352176</td>\n",
              "      <td>0.843941</td>\n",
              "      <td>0.129669</td>\n",
              "      <td>-0.884893</td>\n",
              "      <td>0.514116</td>\n",
              "      <td>0.452871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.595390</td>\n",
              "      <td>0.359039</td>\n",
              "      <td>0.844404</td>\n",
              "      <td>0.125684</td>\n",
              "      <td>-0.888177</td>\n",
              "      <td>0.513920</td>\n",
              "      <td>0.445123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.596375</td>\n",
              "      <td>0.365293</td>\n",
              "      <td>0.844948</td>\n",
              "      <td>0.122067</td>\n",
              "      <td>-0.891349</td>\n",
              "      <td>0.513969</td>\n",
              "      <td>0.438089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.597261</td>\n",
              "      <td>0.371062</td>\n",
              "      <td>0.845436</td>\n",
              "      <td>0.118742</td>\n",
              "      <td>-0.894292</td>\n",
              "      <td>0.514017</td>\n",
              "      <td>0.431622</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      1_0_0     1_0_1     1_1_0     1_1_1     2_0_0     2_0_1     2_0_2\n",
              "0 -0.563676  0.355707  0.826498  0.127656 -0.866058  0.484198  0.448856\n",
              "1 -0.594539  0.352176  0.843941  0.129669 -0.884893  0.514116  0.452871\n",
              "2 -0.595390  0.359039  0.844404  0.125684 -0.888177  0.513920  0.445123\n",
              "3 -0.596375  0.365293  0.844948  0.122067 -0.891349  0.513969  0.438089\n",
              "4 -0.597261  0.371062  0.845436  0.118742 -0.894292  0.514017  0.431622"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'MSE'"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[17.10054083366001,\n",
              " 0.07862929025724717,\n",
              " 0.05669097270973059,\n",
              " 0.04758631353169853,\n",
              " 0.04013037964451527]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEwuMi2DkFWq"
      },
      "source": [
        "# Example 9 -- mrelu check. working"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ay2oPnEzpHR3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 947
        },
        "outputId": "af6a4265-fe33-4dc6-9210-b7cdef169c21"
      },
      "source": [
        "mln4 = MultiLayerNeuron(layers=[1,2,1]) # generating MLN with random weights\n",
        "mln4.set_activ('mrelu', param=0.1)\n",
        "# mln4.set_activ('relu')\n",
        "mln4.set_output_activ('linear')\n",
        "mln4.set_weights([[[-1.1,1.74],[3.35,-6.44]],[[-1.41,2.05,2.2]]]) # setting weights\n",
        "mln4.printWeights()\n",
        "\n",
        "y4=[] # generating output values\n",
        "y4.append(mln4.run([0])[0])\n",
        "y4.append(mln4.run([1])[0])\n",
        "y4.append(mln4.run([2])[0])\n",
        "y4.append(mln4.run([3])[0])\n",
        "y4.append(mln4.run([4])[0])\n",
        "y4.append(mln4.run([5])[0])\n",
        "display ('original values:',y4)\n",
        "print ()\n",
        "\n",
        "# training model and predicting values\n",
        "mln4 = MultiLayerNeuron(layers=[1,2,1], eta=0.005) # generating MLN with random weights\n",
        "mln4.set_activ('mrelu', param=0.1)\n",
        "# mln4.set_activ('relu')\n",
        "mln4.set_output_activ('linear')\n",
        "\n",
        "for i in range(4000):\n",
        "    MSE = 0.0\n",
        "    MSE += mln4.bp_regres([0],y4[0])\n",
        "    MSE += mln4.bp_regres([1],y4[1])\n",
        "    MSE += mln4.bp_regres([2],y4[2])\n",
        "    MSE += mln4.bp_regres([3],y4[3])\n",
        "    MSE += mln4.bp_regres([4],y4[4])\n",
        "    MSE += mln4.bp_regres([5],y4[5])\n",
        "    MSE = MSE / 6\n",
        "    if(i%200 == 0):\n",
        "        print ('MSE', i, '=',MSE)\n",
        "mln4.printWeights()\n",
        "\n",
        "y4=[]\n",
        "y4.append(mln4.run([0])[0])\n",
        "y4.append(mln4.run([1])[0])\n",
        "y4.append(mln4.run([2])[0])\n",
        "y4.append(mln4.run([3])[0])\n",
        "y4.append(mln4.run([4])[0])\n",
        "y4.append(mln4.run([5])[0])\n",
        "display ('predicted values:',y4)\n",
        "print ()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Layer 0 is the Input Layer\n",
            "Layer 1 Neuron 0 : [-1.1   1.74] mrelu\n",
            "Layer 1 Neuron 1 : [ 3.35 -6.44] mrelu\n",
            "Layer 2 Neuron 0 : [-1.41  2.05  2.2 ] linear\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'original values:'"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[-1.5735999999999999,\n",
              " 0.6641500000000005,\n",
              " 2.7978599999999996,\n",
              " 9.82046,\n",
              " 16.843059999999998,\n",
              " 23.865659999999995]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "MSE 0 = 319.05019939953627\n",
            "MSE 200 = 0.6951426098067065\n",
            "MSE 400 = 0.22160963069218295\n",
            "MSE 600 = 0.038335772238223896\n",
            "MSE 800 = 0.0053441210842693695\n",
            "MSE 1000 = 0.0006976859363124628\n",
            "MSE 1200 = 8.858123950547307e-05\n",
            "MSE 1400 = 1.1121992147017414e-05\n",
            "MSE 1600 = 1.4003900112660313e-06\n",
            "MSE 1800 = 1.7527104669866588e-07\n",
            "MSE 2000 = 2.194580125992845e-08\n",
            "MSE 2200 = 2.758372607375086e-09\n",
            "MSE 2400 = 3.4524659435027884e-10\n",
            "MSE 2600 = 4.3224963991211035e-11\n",
            "MSE 2800 = 5.432727110224384e-12\n",
            "MSE 3000 = 6.79864314454025e-13\n",
            "MSE 3200 = 8.54234247597829e-14\n",
            "MSE 3400 = 1.0697395713300622e-14\n",
            "MSE 3600 = 1.3389536565908188e-15\n",
            "MSE 3800 = 1.682461666978609e-16\n",
            "\n",
            "Layer 0 is the Input Layer\n",
            "Layer 1 Neuron 0 : [-1.10734436  1.10734436] mrelu\n",
            "Layer 1 Neuron 1 : [ 1.94400566 -3.48168794] mrelu\n",
            "Layer 2 Neuron 0 : [-1.4006483   3.53265433  1.20735999] linear\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'predicted values:'"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[-1.5735999984081446,\n",
              " 0.6641499948229865,\n",
              " 2.7978600009735066,\n",
              " 9.820460000334313,\n",
              " 16.843059999695118,\n",
              " 23.865659999055925]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8pAh-iAkiJw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "358ff76e-0b07-4680-ff7b-fec2efbdae19"
      },
      "source": [
        "reg2=Regres(layers=[1,2,1], eta=0.01)\n",
        "X=[[1],[2],[3],[4],[5]]\n",
        "# y=[1,4,9,16,25]\n",
        "y=[1,2,3,4,5]\n",
        "reg2.set_hidden_activ('mrelu', param=0.01)\n",
        "reg2.fit(X,y,epochs=15)\n",
        "reg2.printWeights()\n",
        "pred=reg2.predict(X)\n",
        "print ('predictions',pred)\n",
        "display ('weight_history_table',reg2.weight_history_table)\n",
        "# display ('MSE',reg2.MSE_history)\n",
        "\n",
        "fig=px.line(y=reg2.MSE_history)\n",
        "fig.show()"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model fitted.\n",
            "self.weight_history - list of lists of weights propagation\n",
            "self.weight_history_table - pandas table of weights propagation\n",
            "self.MSE_history - list of MSEs propagation\n",
            "\n",
            "Layer 0 is the Input Layer\n",
            "Layer 1 Neuron 0 : [-0.26925859  0.71270123] mrelu\n",
            "Layer 1 Neuron 1 : [-0.26250039 -0.71654462] mrelu\n",
            "Layer 2 Neuron 0 : [-0.11510467 -0.48291081  2.21800192] linear\n",
            "\n",
            "predictions [2.1669595976554215, 2.1979525193538616, 2.2180019188997604, 2.2180019188997604, 2.2180019188997604]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'weight_history_table'"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1_0_0</th>\n",
              "      <th>1_0_1</th>\n",
              "      <th>1_1_0</th>\n",
              "      <th>1_1_1</th>\n",
              "      <th>2_0_0</th>\n",
              "      <th>2_0_1</th>\n",
              "      <th>2_0_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.183020</td>\n",
              "      <td>0.752149</td>\n",
              "      <td>-0.2625</td>\n",
              "      <td>-0.716545</td>\n",
              "      <td>-0.179472</td>\n",
              "      <td>-0.482911</td>\n",
              "      <td>-0.379000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.232845</td>\n",
              "      <td>0.729385</td>\n",
              "      <td>-0.2625</td>\n",
              "      <td>-0.716545</td>\n",
              "      <td>-0.136345</td>\n",
              "      <td>-0.482911</td>\n",
              "      <td>-0.047097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.246191</td>\n",
              "      <td>0.721192</td>\n",
              "      <td>-0.2625</td>\n",
              "      <td>-0.716545</td>\n",
              "      <td>-0.114802</td>\n",
              "      <td>-0.482911</td>\n",
              "      <td>0.251396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.255564</td>\n",
              "      <td>0.715583</td>\n",
              "      <td>-0.2625</td>\n",
              "      <td>-0.716545</td>\n",
              "      <td>-0.099329</td>\n",
              "      <td>-0.482911</td>\n",
              "      <td>0.520818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.262231</td>\n",
              "      <td>0.711728</td>\n",
              "      <td>-0.2625</td>\n",
              "      <td>-0.716545</td>\n",
              "      <td>-0.088509</td>\n",
              "      <td>-0.482911</td>\n",
              "      <td>0.764098</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-0.267008</td>\n",
              "      <td>0.709096</td>\n",
              "      <td>-0.2625</td>\n",
              "      <td>-0.716545</td>\n",
              "      <td>-0.081399</td>\n",
              "      <td>-0.482911</td>\n",
              "      <td>0.983838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-0.270425</td>\n",
              "      <td>0.707345</td>\n",
              "      <td>-0.2625</td>\n",
              "      <td>-0.716545</td>\n",
              "      <td>-0.077339</td>\n",
              "      <td>-0.482911</td>\n",
              "      <td>1.182361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>-0.272818</td>\n",
              "      <td>0.706263</td>\n",
              "      <td>-0.2625</td>\n",
              "      <td>-0.716545</td>\n",
              "      <td>-0.075850</td>\n",
              "      <td>-0.482911</td>\n",
              "      <td>1.361751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>-0.274389</td>\n",
              "      <td>0.705727</td>\n",
              "      <td>-0.2625</td>\n",
              "      <td>-0.716545</td>\n",
              "      <td>-0.076569</td>\n",
              "      <td>-0.482911</td>\n",
              "      <td>1.523880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>-0.275249</td>\n",
              "      <td>0.705673</td>\n",
              "      <td>-0.2625</td>\n",
              "      <td>-0.716545</td>\n",
              "      <td>-0.079215</td>\n",
              "      <td>-0.482911</td>\n",
              "      <td>1.670438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>-0.275446</td>\n",
              "      <td>0.706078</td>\n",
              "      <td>-0.2625</td>\n",
              "      <td>-0.716545</td>\n",
              "      <td>-0.083567</td>\n",
              "      <td>-0.482911</td>\n",
              "      <td>1.802944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>-0.274982</td>\n",
              "      <td>0.706951</td>\n",
              "      <td>-0.2625</td>\n",
              "      <td>-0.716545</td>\n",
              "      <td>-0.089452</td>\n",
              "      <td>-0.482911</td>\n",
              "      <td>1.922771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>-0.273830</td>\n",
              "      <td>0.708318</td>\n",
              "      <td>-0.2625</td>\n",
              "      <td>-0.716545</td>\n",
              "      <td>-0.096732</td>\n",
              "      <td>-0.482911</td>\n",
              "      <td>2.031160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>-0.271942</td>\n",
              "      <td>0.710219</td>\n",
              "      <td>-0.2625</td>\n",
              "      <td>-0.716545</td>\n",
              "      <td>-0.105307</td>\n",
              "      <td>-0.482911</td>\n",
              "      <td>2.129232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>-0.269259</td>\n",
              "      <td>0.712701</td>\n",
              "      <td>-0.2625</td>\n",
              "      <td>-0.716545</td>\n",
              "      <td>-0.115105</td>\n",
              "      <td>-0.482911</td>\n",
              "      <td>2.218002</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       1_0_0     1_0_1   1_1_0     1_1_1     2_0_0     2_0_1     2_0_2\n",
              "0  -0.183020  0.752149 -0.2625 -0.716545 -0.179472 -0.482911 -0.379000\n",
              "1  -0.232845  0.729385 -0.2625 -0.716545 -0.136345 -0.482911 -0.047097\n",
              "2  -0.246191  0.721192 -0.2625 -0.716545 -0.114802 -0.482911  0.251396\n",
              "3  -0.255564  0.715583 -0.2625 -0.716545 -0.099329 -0.482911  0.520818\n",
              "4  -0.262231  0.711728 -0.2625 -0.716545 -0.088509 -0.482911  0.764098\n",
              "5  -0.267008  0.709096 -0.2625 -0.716545 -0.081399 -0.482911  0.983838\n",
              "6  -0.270425  0.707345 -0.2625 -0.716545 -0.077339 -0.482911  1.182361\n",
              "7  -0.272818  0.706263 -0.2625 -0.716545 -0.075850 -0.482911  1.361751\n",
              "8  -0.274389  0.705727 -0.2625 -0.716545 -0.076569 -0.482911  1.523880\n",
              "9  -0.275249  0.705673 -0.2625 -0.716545 -0.079215 -0.482911  1.670438\n",
              "10 -0.275446  0.706078 -0.2625 -0.716545 -0.083567 -0.482911  1.802944\n",
              "11 -0.274982  0.706951 -0.2625 -0.716545 -0.089452 -0.482911  1.922771\n",
              "12 -0.273830  0.708318 -0.2625 -0.716545 -0.096732 -0.482911  2.031160\n",
              "13 -0.271942  0.710219 -0.2625 -0.716545 -0.105307 -0.482911  2.129232\n",
              "14 -0.269259  0.712701 -0.2625 -0.716545 -0.115105 -0.482911  2.218002"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"da21e9a7-93c1-4de5-93d8-38f25236222f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"da21e9a7-93c1-4de5-93d8-38f25236222f\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'da21e9a7-93c1-4de5-93d8-38f25236222f',\n",
              "                        [{\"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"y=%{y}\", \"legendgroup\": \"\", \"line\": {\"color\": \"#636efa\", \"dash\": \"solid\"}, \"mode\": \"lines\", \"name\": \"\", \"showlegend\": false, \"type\": \"scatter\", \"xaxis\": \"x\", \"y\": [78.18515651470793, 50.78107932047711, 42.60140683126787, 36.13711660018821, 30.890387519538553, 26.625816847196727, 23.15640224618426, 20.332071198041564, 18.031680100358688, 16.15709401644859, 14.62863885532666, 13.381525944155186, 12.363001173736297, 11.530052601743243, 10.847557892498774], \"yaxis\": \"y\"}],\n",
              "                        {\"legend\": {\"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0]}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"y\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('da21e9a7-93c1-4de5-93d8-38f25236222f');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbY6a4iUn46K",
        "outputId": "a3dce10f-06a4-4af5-db25-e520ec1e1def",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "source": [
        "history=reg2.weight_history_table.T\n",
        "# history\n",
        "fig=px.parallel_coordinates(history)\n",
        "fig.show()"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"2cd6c45a-3d28-4598-ac96-56b0af1cab07\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"2cd6c45a-3d28-4598-ac96-56b0af1cab07\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '2cd6c45a-3d28-4598-ac96-56b0af1cab07',\n",
              "                        [{\"dimensions\": [{\"label\": \"0\", \"values\": [-0.18301992803485334, 0.7521492717258448, -0.2625003876307588, -0.7165446249825398, -0.17947194692805454, -0.4829108108626363, -0.37900038920585294]}, {\"label\": \"1\", \"values\": [-0.23284473195762942, 0.7293845102500497, -0.2625003876307588, -0.7165446249825398, -0.13634460827995484, -0.4829108108626363, -0.047096893009352395]}, {\"label\": \"2\", \"values\": [-0.24619065054309555, 0.7211915847892979, -0.2625003876307588, -0.7165446249825398, -0.11480212268806858, -0.4829108108626363, 0.2513964007158614]}, {\"label\": \"3\", \"values\": [-0.2555644817310625, 0.7155826534946628, -0.2625003876307588, -0.7165446249825398, -0.09932869839827832, -0.4829108108626363, 0.5208178735894974]}, {\"label\": \"4\", \"values\": [-0.2622307076869526, 0.7117281888792389, -0.2625003876307588, -0.7165446249825398, -0.0885093755581934, -0.4829108108626363, 0.7640981932506216]}, {\"label\": \"5\", \"values\": [-0.2670077910988392, 0.7090956387310525, -0.2625003876307588, -0.7165446249825398, -0.08139937794301734, -0.4829108108626363, 0.9838381095420405]}, {\"label\": \"6\", \"values\": [-0.27042497811250493, 0.7073445974296786, -0.2625003876307588, -0.7165446249825398, -0.07733945513942209, -0.4829108108626363, 1.1823609705571203]}, {\"label\": \"7\", \"values\": [-0.2728177630221754, 0.7062631080836684, -0.2625003876307588, -0.7165446249825398, -0.07584989780574894, -0.4829108108626363, 1.3617505474839198]}, {\"label\": \"8\", \"values\": [-0.2743889666986714, 0.7057269566580779, -0.2625003876307588, -0.7165446249825398, -0.07656865982608511, -0.4829108108626363, 1.523880352572637]}, {\"label\": \"9\", \"values\": [-0.2752494740344422, 0.7056725428455434, -0.2625003876307588, -0.7165446249825398, -0.07921491143920774, -0.4829108108626363, 1.670437599671394]}, {\"label\": \"10\", \"values\": [-0.27544628626308965, 0.7060782142250418, -0.2625003876307588, -0.7165446249825398, -0.08356745279423049, -0.4829108108626363, 1.8029435155812952]}, {\"label\": \"11\", \"values\": [-0.2749822520410652, 0.7069511575161753, -0.2625003876307588, -0.7165446249825398, -0.08945181191186556, -0.4829108108626363, 1.9227709840210034]}, {\"label\": \"12\", \"values\": [-0.27383009236147804, 0.7083181081818938, -0.2625003876307588, -0.7165446249825398, -0.09673235346739532, -0.4829108108626363, 2.031160119367006]}, {\"label\": \"13\", \"values\": [-0.2719423787935407, 0.7102187747297599, -0.2625003876307588, -0.7165446249825398, -0.10530720201587095, -0.4829108108626363, 2.1292321559057084]}, {\"label\": \"14\", \"values\": [-0.2692585852122358, 0.7127012311790694, -0.2625003876307588, -0.7165446249825398, -0.11510467409613243, -0.4829108108626363, 2.2180019188997604]}], \"domain\": {\"x\": [0.0, 1.0], \"y\": [0.0, 1.0]}, \"name\": \"\", \"type\": \"parcoords\"}],\n",
              "                        {\"legend\": {\"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('2cd6c45a-3d28-4598-ac96-56b0af1cab07');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}