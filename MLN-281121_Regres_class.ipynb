{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vladgap/Various/blob/main/MLN-281121_Regres_class.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWfs6xKyIiBC"
      },
      "source": [
        "import numpy as np\n",
        "# import pandas as pd\n",
        "from sklearn import preprocessing"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VG50azfXte36"
      },
      "source": [
        "# StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jn6l3WGso4QY",
        "outputId": "5c63446c-172b-43b4-9160-fcc13334c114"
      },
      "source": [
        "x=[\n",
        "[2,1,0],\n",
        "[-1,0,1],\n",
        "[0,0,0],\n",
        "[1,1,0],\n",
        "[-1,-1,-1],\n",
        "[-1,1,-1],\n",
        "]\n",
        "# x=np.array(x)\n",
        "scaler = preprocessing.StandardScaler().fit(x)\n",
        "print(scaler.mean_, scaler.scale_)\n",
        "x_scaled = scaler.transform(x)\n",
        "print (x_scaled)\n",
        "x_back=scaler.inverse_transform(x_scaled)\n",
        "print (x_back)\n",
        "scaler.inverse_transform([[0,0,0]])\n",
        "# help(scaler)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.          0.33333333 -0.16666667] [1.15470054 0.74535599 0.68718427]\n",
            "[[ 1.73205081  0.89442719  0.24253563]\n",
            " [-0.8660254  -0.4472136   1.69774938]\n",
            " [ 0.         -0.4472136   0.24253563]\n",
            " [ 0.8660254   0.89442719  0.24253563]\n",
            " [-0.8660254  -1.78885438 -1.21267813]\n",
            " [-0.8660254   0.89442719 -1.21267813]]\n",
            "[[ 2.  1.  0.]\n",
            " [-1.  0.  1.]\n",
            " [ 0.  0.  0.]\n",
            " [ 1.  1.  0.]\n",
            " [-1. -1. -1.]\n",
            " [-1.  1. -1.]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.        ,  0.33333333, -0.16666667]])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUCN7lc5sieC"
      },
      "source": [
        "# Single Neuron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSEiZemKj3xT"
      },
      "source": [
        "class Neuron:\n",
        "    \"\"\"A single neuron with an activation function.\n",
        "       Attributes:\n",
        "          inputs: The number of inputs in the perceptron, not counting the bias.\n",
        "          bias:   The bias term. By defaul it's 1.0.\n",
        "          activ:  The activation function: linear (default), relu, sigmoid.\"\"\"\n",
        "\n",
        "    def __init__(self, inputs, bias = 1.0, activ = 'linear'):\n",
        "        \"\"\"Return a new Perceptron object with the specified number of inputs (+1 for the bias) and random initial weights.\"\"\" \n",
        "        self.weights = (np.random.rand(inputs+1) * 2) - 1 \n",
        "        self.bias = bias\n",
        "        self.activ = activ\n",
        "\n",
        "    def run(self, x):\n",
        "        \"\"\"Run the perceptron. x is a python list with the input values.\"\"\"\n",
        "        sum = np.dot(np.append(x,self.bias),self.weights)\n",
        "        if self.activ == 'linear':\n",
        "          return sum\n",
        "        if self.activ == 'sigmoid':\n",
        "          return self.sigmoid(sum)\n",
        "        if self.activ == 'relu':\n",
        "          return self.relu(sum)\n",
        "        if self.activ == 'mrelu':\n",
        "          return self.mrelu(sum)\n",
        "\n",
        "    def set_weights(self, w_init):\n",
        "        \"\"\"Overrides the np.random.rand() weights and the bias weight.\"\"\"\n",
        "        # w_init is a list of floats. Organize it as you'd like.\n",
        "        self.weights=np.array(w_init)\n",
        "\n",
        "    def set_activ(self, activ, param=0):\n",
        "        \"\"\"Overrides the 'linear' activation function.\"\"\"\n",
        "        self.activ = activ\n",
        "        self.param = param\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        # return the output of the sigmoid function applied to x\n",
        "        return 1/(1+np.exp(-x))\n",
        "    \n",
        "    def relu(self, x):\n",
        "        # return the output of the relu function applied to x\n",
        "        if x >= 0:\n",
        "          return x\n",
        "        return 0\n",
        "\n",
        "    def mrelu(self, x):\n",
        "        # return the output of the modified relu function applied to x\n",
        "        if x >= 0:\n",
        "          return x\n",
        "        return self.param*x"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cweRHa4rXfX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ec6e886-5504-4ce5-cba1-5b91bc90a00d"
      },
      "source": [
        "4>=4"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nN9wRG3NlI4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb2c8203-b2b3-4200-9ce2-22739c8b8a11"
      },
      "source": [
        "neu=Neuron(inputs=2)\n",
        "neu.set_weights([10,10,-15]) \n",
        "neu.set_activ('mrelu', param=0.01)\n",
        "neu.run([1,0])"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.05"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bo32Xuop0eYO"
      },
      "source": [
        "## AND gate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeLvN9yxHGsw",
        "outputId": "6d6f40ea-7a71-421d-d1fa-d2c6c27beb0c"
      },
      "source": [
        "neuron = Neuron(inputs=2, activ='sigmoid')\n",
        "neuron.set_weights([10,10,-15]) #AND gate\n",
        "\n",
        "print(\"AND Gate:\")\n",
        "print (\"0 0 = {0:.10f}\".format(neuron.run([0,0])))\n",
        "print (\"0 1 = {0:.10f}\".format(neuron.run([0,1])))\n",
        "print (\"1 0 = {0:.10f}\".format(neuron.run([1,0])))\n",
        "print (\"1 1 = {0:.10f}\".format(neuron.run([1,1])))\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AND Gate:\n",
            "0 0 = 0.0000003059\n",
            "0 1 = 0.0066928509\n",
            "1 0 = 0.0066928509\n",
            "1 1 = 0.9933071491\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDiUtQWL2qFC"
      },
      "source": [
        "## OR gate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJy3bJjS2qhO",
        "outputId": "b714908c-09d7-43a2-9798-9faa608bc47e"
      },
      "source": [
        "neuron = Neuron(inputs=2, activ='sigmoid')\n",
        "neuron.set_weights([10,10,-5]) #OR gate\n",
        "\n",
        "print(\"OR Gate:\")\n",
        "print (\"0 0 = {0:.10f}\".format(neuron.run([0,0])))\n",
        "print (\"0 1 = {0:.10f}\".format(neuron.run([0,1])))\n",
        "print (\"1 0 = {0:.10f}\".format(neuron.run([1,0])))\n",
        "print (\"1 1 = {0:.10f}\".format(neuron.run([1,1])))\n"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OR Gate:\n",
            "0 0 = 0.0066928509\n",
            "0 1 = 0.9933071491\n",
            "1 0 = 0.9933071491\n",
            "1 1 = 0.9999996941\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CyK0jOA4vGH"
      },
      "source": [
        "## NAND gate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XH_wkvCq4vpB",
        "outputId": "e1b37e1f-e8a6-425d-b2ec-4be9f738cf03"
      },
      "source": [
        "neuron = Neuron(inputs=2, activ='sigmoid')\n",
        "neuron.set_weights([-10,-10,15]) #NAND gate\n",
        "\n",
        "print(\"NAND Gate:\")\n",
        "print (\"0 0 = {0:.10f}\".format(neuron.run([0,0])))\n",
        "print (\"0 1 = {0:.10f}\".format(neuron.run([0,1])))\n",
        "print (\"1 0 = {0:.10f}\".format(neuron.run([1,0])))\n",
        "print (\"1 1 = {0:.10f}\".format(neuron.run([1,1])))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NAND Gate:\n",
            "0 0 = 0.9999996941\n",
            "0 1 = 0.9933071491\n",
            "1 0 = 0.9933071491\n",
            "1 1 = 0.0066928509\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rpjT9eO6LeS"
      },
      "source": [
        "# Multilayer neuron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "My-snyukphuZ"
      },
      "source": [
        "class MultiLayerNeuron:     \n",
        "    \"\"\"A multilayer neuron class that uses the Neuron class above.\n",
        "       Builds a list of neurons with the specific activation function.\n",
        "       The activation function may be modified later using the set_activ method.\n",
        "       For example: mln.network[layer][neuron].set_activ('linear').\n",
        "       Attributes:\n",
        "          layers:  A list with the number of neurons per layer. Including the input (first) and the output (last) layers.\n",
        "          bias:    The bias term. The same bias is used for all neurons.\n",
        "          eta:     The learning rate.\n",
        "          activ:   The activation function: linear (default), relu, sigmoid.\"\"\"\n",
        "\n",
        "    def __init__(self, layers, bias = 1.0, eta = 0.5, activ='linear'):\n",
        "        \"\"\"Return a new MLP object with the specified parameters.\"\"\" \n",
        "        self.layers = np.array(layers,dtype=object)\n",
        "        self.bias = bias\n",
        "        self.eta = eta\n",
        "        self.network = [] # The list of lists of neurons (perceptrons).\n",
        "        self.values = []  # The list of lists of neurons' (perceptrons') output values.\n",
        "        self.d = []       # The list of lists of error terms (lowercase deltas)\n",
        "        self.activ = activ\n",
        "\n",
        "        # 2 nested loops to create neurons layer by layer\n",
        "        for i in range(len(self.layers)): # outer loop iterates on each layer\n",
        "            self.values.append([]) #The new list of values will be filled with zeros, for every neuron in the layer. \n",
        "            self.values[i] = [0.0 for j in range(self.layers[i])]\n",
        "            self.d.append([])\n",
        "            self.d[i] = [0.0 for j in range(self.layers[i])]                        \n",
        "            self.network.append([])\n",
        "            if i > 0:      #network[0] is the input layer, so it has no neurons\n",
        "                for j in range(self.layers[i]): # inner loop iterates on each neuron in a layer\n",
        "                    neur=Neuron(inputs = self.layers[i-1], bias = self.bias, activ = self.activ) # \n",
        "                    self.network[i].append(neur) # adding j perceptrons\n",
        "        \n",
        "        self.network = np.array([np.array(x) for x in self.network],dtype=object) #transforms list of lists to numpy array\n",
        "        self.values = np.array([np.array(x) for x in self.values],dtype=object)\n",
        "        self.d = np.array([np.array(x) for x in self.d],dtype=object)\n",
        "\n",
        "    def set_weights(self, w_init): # set_weights of the MultiLayer class\n",
        "        \"\"\"Set the weights. \n",
        "           w_init is a list of lists with the weights for all but the input layer.\"\"\"\n",
        "        for i in range(len(w_init)):\n",
        "            for j in range(len(w_init[i])):\n",
        "                self.network[i+1][j].set_weights(w_init[i][j]) # set_weights for each perceptron i\n",
        "\n",
        "    def set_activ(self, activ, param=0):\n",
        "        \"\"\"Set the activation function to every neurons.\"\"\"\n",
        "        for i in range(1,len(self.network)):\n",
        "            for j in range(self.layers[i]):\n",
        "                self.network[i][j].set_activ(activ, param) # set_activ for each neuron\n",
        "        self.param=param\n",
        "    \n",
        "    def set_output_activ(self, activ, param=0):\n",
        "        \"\"\"Set the activation function to the last (output) neurons.\"\"\"\n",
        "        i = len(self.network)-1\n",
        "        for j in range(self.layers[i]):\n",
        "            self.network[i][j].set_activ(activ, param) \n",
        "\n",
        "    def printWeights(self):\n",
        "        \"\"\"Displays a summary of weights and activation functions per layer and neuron.\"\"\"\n",
        "        print()\n",
        "        print('Layer 0 is the Input Layer')\n",
        "        for i in range(1,len(self.network)):\n",
        "            for j in range(self.layers[i]):\n",
        "                print(\"Layer\",i,\"Neuron\",j,\":\",self.network[i][j].weights,self.network[i][j].activ)\n",
        "        print()\n",
        "\n",
        "    def run(self, x):\n",
        "        \"\"\"Feed a sample x into the MultiLayer Neuron.\"\"\"\n",
        "        x = np.array(x,dtype=object)\n",
        "        self.values[0] = x\n",
        "        for i in range(1,len(self.network)):\n",
        "            for j in range(self.layers[i]):  \n",
        "                self.values[i][j] = self.network[i][j].run(self.values[i-1]) #runs preceptrons with the previous outputs\n",
        "        return self.values[-1]\n",
        "\n",
        "    def bp_classif(self, x, y):\n",
        "        \"\"\"Run a single (x,y) pair with the backpropagation algorithm - Gradient Descent.\n",
        "        Uses the derivative of the sigmoid function.\"\"\"\n",
        "        x = np.array(x,dtype=object)\n",
        "        y = np.array(y,dtype=object)\n",
        "        # STEP 1: Feed a sample to the network \n",
        "        outputs = self.run(x)\n",
        "        # STEP 2: Calculate the MSE\n",
        "        error = 2*(y - outputs) # A list of outputs\n",
        "        MSE = sum( error ** 2) / self.layers[-1] \n",
        "        # ∂MSE/∂weight=∂MSE/∂output*∂output/∂weight\n",
        "        # STEP 3: Calculate the OUTPUT error terms\n",
        "        # ∂MSE/∂output -- depends on neuron's activation function\n",
        "        self.d[-1] = outputs * (1 - outputs) * (error) # derivative of the SIGMOID function \n",
        "        # STEP 4: Calculate the error term of EACH UNIT on each layer\n",
        "        for i in reversed(range(1,len(self.network)-1)):\n",
        "            for h in range(len(self.network[i])):\n",
        "                fwd_error = 0.0\n",
        "                for k in range(self.layers[i+1]): \n",
        "                    fwd_error += self.network[i+1][k].weights[h] * self.d[i+1][k]               \n",
        "                self.d[i][h] = self.values[i][h] * (1-self.values[i][h]) * fwd_error # derivative of the SIGMOID function\n",
        "        # STEPS 5 & 6: Calculate the deltas and update the weights\n",
        "        for i in range(1,len(self.network)): # runs on layers\n",
        "            for j in range(self.layers[i]): # runs on neurons\n",
        "                for k in range(self.layers[i-1]+1): # runs on inputs. +1 for bias\n",
        "                    if k==self.layers[i-1]:\n",
        "                        delta = self.eta * self.d[i][j] * self.bias\n",
        "                    else:\n",
        "                        delta = self.eta * self.d[i][j] * self.values[i-1][k] # applying the delta rule\n",
        "                    self.network[i][j].weights[k] += delta\n",
        "        return MSE\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        # return the output of the sigmoid function applied to x\n",
        "        return 1/(1+np.exp(-x))\n",
        "\n",
        "    def deriv(self, value, i, j=0):\n",
        "        if self.network[i][j].activ == 'linear':\n",
        "          # print ('lin')\n",
        "          return 1\n",
        "        if self.network[i][j].activ == 'sigmoid':\n",
        "          # print ('sig')\n",
        "          return self.sigmoid(value)*(1-self.sigmoid(value))\n",
        "        if self.network[i][j].activ == 'relu':\n",
        "          if value > 0:\n",
        "            # print ('re>')\n",
        "            return 1\n",
        "          else:\n",
        "            # print ('re<')\n",
        "            return 0\n",
        "        if self.network[i][j].activ == 'mrelu':\n",
        "          if value > 0:\n",
        "            return 1\n",
        "          else:\n",
        "            return self.param\n",
        "\n",
        "    def bp_regres(self, x, y):\n",
        "        \"\"\"Run a single (x,y) pair with the backpropagation algorithm - Gradient Descent.\n",
        "        Uses the derivative according each neuron's activation function.\"\"\"\n",
        "        x = np.array(x,dtype=object)\n",
        "        y = np.array(y,dtype=object)\n",
        "        # STEP 1: Feed a sample to the network \n",
        "        outputs = self.run(x)\n",
        "        # STEP 2: Calculate the MSE\n",
        "        error = 2*(y - outputs) # A list of outputs\n",
        "        MSE = sum( error ** 2) / self.layers[-1] \n",
        "        # ∂MSE/∂weight=∂MSE/∂output*∂output/∂weight\n",
        "        # STEP 3: Calculate the OUTPUT error terms\n",
        "        # ∂MSE/∂output -- depends on neuron's activation function\n",
        "        for j in range (len(outputs)):\n",
        "            self.d[-1][j] = self.deriv(outputs[j], len(self.network)-1) * error\n",
        "        # STEP 4: Calculate the error term of EACH UNIT on each layer\n",
        "        for i in reversed(range(1,len(self.network)-1)):\n",
        "            for h in range(len(self.network[i])):\n",
        "                fwd_error = 0.0\n",
        "                for k in range(self.layers[i+1]): \n",
        "                    fwd_error += self.network[i+1][k].weights[h] * self.d[i+1][k] \n",
        "                self.d[i][h] = self.deriv(self.values[i][h], i, h) * fwd_error\n",
        "        # STEPS 5 & 6: Calculate the deltas and update the weights\n",
        "        for i in range(1,len(self.network)): # runs on layers\n",
        "            for j in range(self.layers[i]): # runs on neurons\n",
        "                for k in range(self.layers[i-1]+1): # runs on inputs. +1 for bias\n",
        "                    # output=sum(weight*value)+bias*bias_weight\n",
        "                    if k==self.layers[i-1]:\n",
        "                        # ∂output/∂bias_weight=bias\n",
        "                        delta = self.eta * self.d[i][j] * self.bias\n",
        "                    else:\n",
        "                        # ∂output/∂weight=value\n",
        "                        delta = self.eta * self.d[i][j] * self.values[i-1][k] \n",
        "                    self.network[i][j].weights[k] += delta # applying the delta rule\n",
        "        return MSE"
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlSin4uPzSFX"
      },
      "source": [
        "## XOR gate=(OR+NAND)+AND"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2dcROXuqJT1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e4bb0c6-eb16-4417-aeb1-f0b81625940e"
      },
      "source": [
        "#test code\n",
        "mln1 = MultiLayerNeuron(layers=[2,2,1])  #mln1\n",
        "mln1.set_weights([[[-10,-10,15],[15,15,-10]],[[10,10,-15]]])\n",
        "mln1.set_activ('sigmoid') #linear is by default\n",
        "\n",
        "mln1.printWeights()\n",
        "print(\"XOR Gate:\")\n",
        "print (\"0 0 = {0:.10f}\".format(mln1.run([0,0])[0]))\n",
        "print (\"0 1 = {0:.10f}\".format(mln1.run([0,1])[0]))\n",
        "print (\"1 0 = {0:.10f}\".format(mln1.run([1,0])[0]))\n",
        "print (\"1 1 = {0:.10f}\".format(mln1.run([1,1])[0]))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Layer 0 is the Input Layer\n",
            "Layer 1 Neuron 0 : [-10 -10  15] sigmoid\n",
            "Layer 1 Neuron 1 : [ 15  15 -10] sigmoid\n",
            "Layer 2 Neuron 0 : [ 10  10 -15] sigmoid\n",
            "\n",
            "XOR Gate:\n",
            "0 0 = 0.0066958493\n",
            "0 1 = 0.9923558642\n",
            "1 0 = 0.9923558642\n",
            "1 1 = 0.0071528098\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBf5fifWK_EG"
      },
      "source": [
        "## Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaZYikTxNp69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6f405b6-1ab1-4704-fbc0-9e0a5a1f4bcc"
      },
      "source": [
        "mln2 = MultiLayerNeuron(layers=[2,2,1])\n",
        "mln2.set_activ('sigmoid') #linear is by default\n",
        "print(\"\\nTraining Neural Network as an XOR Gate...\\n\")\n",
        "for i in range(2000):\n",
        "    MSE = 0.0\n",
        "    MSE += mln2.bp_classif([0,0],[0])\n",
        "    MSE += mln2.bp_classif([0,1],[1])\n",
        "    MSE += mln2.bp_classif([1,0],[1])\n",
        "    MSE += mln2.bp_classif([1,1],[0])\n",
        "    MSE = MSE / 4\n",
        "    if(i%200 == 0):\n",
        "        print (MSE)\n",
        "\n",
        "mln2.printWeights()\n",
        "    \n",
        "print(\"XOR Gate:\")\n",
        "print (\"0 0 = {0:.10f}\".format(mln2.run([0,0])[0]))\n",
        "print (\"0 1 = {0:.10f}\".format(mln2.run([0,1])[0]))\n",
        "print (\"1 0 = {0:.10f}\".format(mln2.run([1,0])[0]))\n",
        "print (\"1 1 = {0:.10f}\".format(mln2.run([1,1])[0]))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Neural Network as an XOR Gate...\n",
            "\n",
            "1.1034003191636055\n",
            "1.0693832090570776\n",
            "0.8677396198411216\n",
            "0.6312101578380522\n",
            "0.06632064300724003\n",
            "0.0228574228664142\n",
            "0.013176348921201316\n",
            "0.009117910172248831\n",
            "0.006921752807609517\n",
            "0.005556001943169528\n",
            "\n",
            "Layer 0 is the Input Layer\n",
            "Layer 1 Neuron 0 : [-6.14667767 -6.14271178  2.41430799] sigmoid\n",
            "Layer 1 Neuron 1 : [-4.30869095 -4.30444496  6.37552695] sigmoid\n",
            "Layer 2 Neuron 0 : [-8.75625995  8.55002672 -3.98658864] sigmoid\n",
            "\n",
            "XOR Gate:\n",
            "0 0 = 0.0296391912\n",
            "0 1 = 0.9677316470\n",
            "1 0 = 0.9676434539\n",
            "1 1 = 0.0405971126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZS1-UADpTpY"
      },
      "source": [
        "# Regres"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkOQ9tbuvI9P"
      },
      "source": [
        "class Regres:\n",
        "    def __init__(self, layers, bias=1.0, eta=0.5, ):\n",
        "        self.layers = layers\n",
        "        self.bias = bias\n",
        "        self.eta = eta\n",
        "        self.regres_network = MultiLayerNeuron(layers=layers, bias=bias, eta=eta)\n",
        "\n",
        "    def set_weights(self, w_init):\n",
        "        self.regres_network.set_weights(w_init)\n",
        "\n",
        "    def set_hidden_activ(self, activ, param=0):\n",
        "        self.regres_network.set_activ(activ, param=0)\n",
        "        self.regres_network.set_output_activ('linear')\n",
        "\n",
        "    def fit(self, X, y, epochs):\n",
        "        self.epochs=epochs\n",
        "        self.weight_history=[]\n",
        "        self.MSE_history=[]\n",
        "        for i in range(self.epochs):\n",
        "            weight_epoch=[]\n",
        "            MSE = 0.0\n",
        "            for j in range (len(X)):\n",
        "                MSE +=  self.regres_network.bp_regres(X[j],[y[j]])\n",
        "            MSE = MSE / len(X)\n",
        "            for m in range(1,len(self.regres_network.network)):\n",
        "                for n in range(self.layers[m]):\n",
        "                    weight_epoch.append(self.regres_network.network[m][n].weights)\n",
        "            self.weight_history.append(weight_epoch)\n",
        "            self.MSE_history.append(MSE)\n",
        "\n",
        "    def printWeights(self):\n",
        "        self.regres_network.printWeights()\n",
        "\n",
        "    def run(self, x):\n",
        "        return self.regres_network.run(x)\n",
        "\n",
        "    def predict(self, x):\n",
        "        y=[]\n",
        "        for i in range(len(x)):\n",
        "            y.append(self.run(x[i])[0])\n",
        "        return y"
      ],
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqJ8FTGSvCrP"
      },
      "source": [
        "# Regres_scale"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zz-y1CtyyZvy"
      },
      "source": [
        "# nuzhno podumat' kak vesa obratno perevesti. mozhet inverse_transform\n",
        "class Regres_scale:\n",
        "    def __init__(self, layers, bias=1.0, eta=0.5, ):\n",
        "        self.layers = layers\n",
        "        self.bias = bias\n",
        "        self.eta = eta\n",
        "        # self.epochs = epochs      \n",
        "        self.regres_network = MultiLayerNeuron(layers=layers, bias=bias, eta=eta)\n",
        "\n",
        "    def set_weights(self, w_init):\n",
        "        self.regres_network.set_weights(w_init)\n",
        "\n",
        "    def set_hidden_activ(self, activ):\n",
        "        self.regres_network.set_activ(activ)\n",
        "        self.regres_network.set_output_activ('linear')\n",
        "\n",
        "    def fit(self, x, y, epochs):\n",
        "        self.scaler = preprocessing.StandardScaler().fit(x)\n",
        "        x_scaled=self.scaler.transform(x)\n",
        "        self.epochs=epochs\n",
        "        for i in range(epochs):\n",
        "            MSE = 0.0\n",
        "            for j in range (len(x)):\n",
        "                MSE +=  self.regres_network.bp_regres(x_scaled[j],[y[j]])\n",
        "            MSE = MSE / len(x)\n",
        "            # dobavit' istoriyu kak v Regres\n",
        "\n",
        "    def printWeights(self):\n",
        "        self.regres_network.printWeights()\n",
        "\n",
        "    def run(self, x):\n",
        "        return self.regres_network.run(x)\n",
        "\n",
        "    def predict(self, x):\n",
        "        y=[]\n",
        "        for i in range(len(x)):\n",
        "            y.append(self.run(x[i])[0])\n",
        "        return y\n",
        "\n",
        "    def get_standard_params(self, x):\n",
        "        x2=np.array(x)\n",
        "        mean=x2.mean(axis=0)\n",
        "        stdev=x2.std(axis=0)\n",
        "        return mean, stdev"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1CIr02vJjVL"
      },
      "source": [
        "# Example1 -- weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1cXJqv6KPD9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30473fa7-8b14-4ce6-b0bf-6e3ccf915d3f"
      },
      "source": [
        "print (\"1 1 =\",mln1.run([1,1]))\n",
        "print (mln1.network[1][0].weights) # network is list of lists of perceptrons. Each has attribute \"weights\""
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 1 = [0.00715281]\n",
            "[-10 -10  15]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mV8ZGDKCGdig",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7bf1363-1108-43ba-94fa-a20cda857156"
      },
      "source": [
        "mln1=MultiLayerNeuron(layers=[2,2,1])\n",
        "mln1.set_activ('relu')\n",
        "mln1.printWeights()\n",
        "\n",
        "mln1.set_output_activ('sigmoid') # setting the output activ func\n",
        "mln1.printWeights()\n",
        "\n",
        "mln1.network[1][0].set_activ('linear') # changing specific activ func\n",
        "mln1.printWeights()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Layer 0 is the Input Layer\n",
            "Layer 1 Neuron 0 : [0.89920023 0.22580934 0.01236954] relu\n",
            "Layer 1 Neuron 1 : [ 0.56378196 -0.31550563  0.9658366 ] relu\n",
            "Layer 2 Neuron 0 : [-0.16169181  0.87379262  0.39717317] relu\n",
            "\n",
            "\n",
            "Layer 0 is the Input Layer\n",
            "Layer 1 Neuron 0 : [0.89920023 0.22580934 0.01236954] relu\n",
            "Layer 1 Neuron 1 : [ 0.56378196 -0.31550563  0.9658366 ] relu\n",
            "Layer 2 Neuron 0 : [-0.16169181  0.87379262  0.39717317] sigmoid\n",
            "\n",
            "\n",
            "Layer 0 is the Input Layer\n",
            "Layer 1 Neuron 0 : [0.89920023 0.22580934 0.01236954] linear\n",
            "Layer 1 Neuron 1 : [ 0.56378196 -0.31550563  0.9658366 ] relu\n",
            "Layer 2 Neuron 0 : [-0.16169181  0.87379262  0.39717317] sigmoid\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NC63zSSKVjl"
      },
      "source": [
        "# Example 2 -- sigmoid, bp_classif, XOR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prBVNR0eNQSC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b447c820-c488-4052-efde-1ddae06125ee"
      },
      "source": [
        "mln2 = MultiLayerNeuron(layers=[2,2,1], eta=0.5)\n",
        "print (mln2.network[1][1].weights)\n",
        "mln2.set_activ('sigmoid') #linear is by default\n",
        "print(\"\\nTraining Neural Network as an XOR Gate...\\n\")\n",
        "for i in range(2000):\n",
        "    MSE = 0.0\n",
        "    MSE += mln2.bp_classif([0,0],[0])\n",
        "    MSE += mln2.bp_classif([0,1],[1])\n",
        "    MSE += mln2.bp_classif([1,0],[1])\n",
        "    MSE += mln2.bp_classif([1,1],[0])\n",
        "    MSE = MSE / 4\n",
        "    if(i%200 == 0):\n",
        "        print (MSE)\n",
        "\n",
        "mln2.printWeights()\n",
        "    \n",
        "print(\"XOR Gate:\")\n",
        "print (\"0 0 = {0:.10f}\".format(mln2.run([0,0])[0]))\n",
        "print (\"0 1 = {0:.10f}\".format(mln2.run([0,1])[0]))\n",
        "print (\"1 0 = {0:.10f}\".format(mln2.run([1,0])[0]))\n",
        "print (\"1 1 = {0:.10f}\".format(mln2.run([1,1])[0]))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.65526687  0.52866591 -0.32701178]\n",
            "\n",
            "Training Neural Network as an XOR Gate...\n",
            "\n",
            "1.1704325926091503\n",
            "1.076266158174247\n",
            "1.043886583872709\n",
            "0.5103941749660728\n",
            "0.049110267984580236\n",
            "0.02034966571699586\n",
            "0.012359226323665144\n",
            "0.008752454513068934\n",
            "0.006728961356711569\n",
            "0.005443750426326519\n",
            "\n",
            "Layer 0 is the Input Layer\n",
            "Layer 1 Neuron 0 : [-5.84782156 -5.85443513  2.22132496] sigmoid\n",
            "Layer 1 Neuron 1 : [ 4.40035021  4.39831416 -6.84625758] sigmoid\n",
            "Layer 2 Neuron 0 : [-8.50509845 -8.64412132  4.21891094] sigmoid\n",
            "\n",
            "XOR Gate:\n",
            "0 0 = 0.0303796643\n",
            "0 1 = 0.9648348281\n",
            "1 0 = 0.9647428988\n",
            "1 1 = 0.0338470156\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFSdNaYSKr7h"
      },
      "source": [
        "# Example 3 -- linear activs, bp_regres"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsu-mr5IdZlt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a14cb2ea-691b-4bcf-cf14-e5749b2097ed"
      },
      "source": [
        "mln3 = MultiLayerNeuron(layers=[3,1], eta=0.3)\n",
        "# mln3.set_weights([[[5.,-0.9,2.,0.]]])\n",
        "mln3.set_weights([[[0.,0.,0.,0.]]])\n",
        "mln3.printWeights()\n",
        "print(\"\\nTraining Neural Network...\\n\")\n",
        "for i in range(400):\n",
        "    MSE = 0.0\n",
        "    MSE += mln3.bp_regres([0.7759,\t0.1104,\t0.9977,],5.764286995)\n",
        "    MSE += mln3.bp_regres([0.9692,\t0.6961,\t0.8483,],5.84646758)\n",
        "    MSE += mln3.bp_regres([0.0265,\t0.399,\t0.5375,],0.808633075)\n",
        "    MSE += mln3.bp_regres([0.7694,\t0.5051,\t0.2542,],3.850298589)\n",
        "    MSE = MSE / 4\n",
        "    if(i%200 == 0):\n",
        "        print (MSE)\n",
        "\n",
        "mln3.printWeights()\n",
        "\n"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Layer 0 is the Input Layer\n",
            "Layer 1 Neuron 0 : [0. 0. 0. 0.] linear\n",
            "\n",
            "\n",
            "Training Neural Network...\n",
            "\n",
            "54.560573414122615\n",
            "9.652321993077698e-13\n",
            "\n",
            "Layer 0 is the Input Layer\n",
            "Layer 1 Neuron 0 : [ 4.99973369e+00 -9.99625006e-01  1.99991681e+00  3.52253294e-05] linear\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVLEXpeKNbYW",
        "outputId": "58503995-78ad-4050-e8b8-105669a15e86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "mln3 = MultiLayerNeuron(layers=[2,1], eta=0.1)\n",
        "# mln3.set_weights([[[2.,1.]]])\n",
        "# mln3.set_weights([[[0.,0.,0.,0.]]])\n",
        "mln3.printWeights()\n",
        "print(\"\\nTraining Neural Network...\\n\")\n",
        "for i in range(400):\n",
        "    MSE = 0.0\n",
        "    MSE += mln3.bp_regres([0.,0.],0.)\n",
        "    MSE += mln3.bp_regres([1.,1.],3.)\n",
        "    MSE += mln3.bp_regres([2.,0.],4.)\n",
        "    MSE += mln3.bp_regres([3.,1.],7.)\n",
        "    MSE = MSE / 4\n",
        "    if(i%200 == 0):\n",
        "        print (MSE)\n",
        "\n",
        "mln3.printWeights()"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Layer 0 is the Input Layer\n",
            "Layer 1 Neuron 0 : [0.68465174 0.99089057 0.61023135] linear\n",
            "\n",
            "\n",
            "Training Neural Network...\n",
            "\n",
            "3.875109727823518\n",
            "9.555017328664439e-46\n",
            "\n",
            "Layer 0 is the Input Layer\n",
            "Layer 1 Neuron 0 : [2.00000000e+00 1.00000000e+00 1.28266469e-42] linear\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8_8y3LEYha1",
        "outputId": "1c608b5b-3a84-479d-b5bc-8147ad52b35e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "mln3 = MultiLayerNeuron(layers=[1,1], eta=0.1)\n",
        "# mln3.set_weights([[[2.,1.]]])\n",
        "# mln3.set_weights([[[0.,0.,0.,0.]]])\n",
        "mln3.printWeights()\n",
        "print(\"\\nTraining Neural Network...\\n\")\n",
        "for i in range(400):\n",
        "    MSE = 0.0\n",
        "    MSE += mln3.bp_regres([0.],0.)\n",
        "    MSE += mln3.bp_regres([1.],2.)\n",
        "    MSE += mln3.bp_regres([2.],4.)\n",
        "    MSE += mln3.bp_regres([3.],6.)\n",
        "    MSE = MSE / 4\n",
        "    if(i%200 == 0):\n",
        "        print (MSE)\n",
        "\n",
        "mln3.printWeights()"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Layer 0 is the Input Layer\n",
            "Layer 1 Neuron 0 : [-0.55949513  0.86399944] linear\n",
            "\n",
            "\n",
            "Training Neural Network...\n",
            "\n",
            "15.916998042547032\n",
            "9.293510831493277e-49\n",
            "\n",
            "Layer 0 is the Input Layer\n",
            "Layer 1 Neuron 0 : [2.00000000e+00 4.00025156e-44] linear\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwlXhDA2KORl"
      },
      "source": [
        "# Example 4 -- sigmoid, bp_regres"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBA-VYuEJGm2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "outputId": "f9e76411-ee96-4316-a258-ea8a86d28748"
      },
      "source": [
        "# generating output values\n",
        "mln4 = MultiLayerNeuron(layers=[3,2,1], eta=0.3)\n",
        "mln4.set_activ('sigmoid')\n",
        "mln4.set_output_activ('linear')\n",
        "mln4.set_weights([[[0,1,-2,1],[1,-2,0,1]],[[-1,2,3]]])\n",
        "mln4.printWeights()\n",
        "\n",
        "y4=[]\n",
        "y4.append(mln4.run([2,1,0])[0])\n",
        "y4.append(mln4.run([-1,0,1])[0])\n",
        "y4.append(mln4.run([0,0,0])[0])\n",
        "y4.append(mln4.run([1,1,0])[0])\n",
        "y4.append(mln4.run([-1,-1,-1])[0])\n",
        "y4.append(mln4.run([-1,1,-1])[0])\n",
        "display ('original values:',y4)\n",
        "print ()\n",
        "\n",
        "# training model and predicting values\n",
        "mln4 = MultiLayerNeuron(layers=[3,2,1], eta=0.3)\n",
        "mln4.set_activ('sigmoid')\n",
        "mln4.set_output_activ('linear')\n",
        "\n",
        "for i in range(1000):\n",
        "    MSE = 0.0\n",
        "    MSE += mln4.bp_regres([2,1,0],y4[0])\n",
        "    MSE += mln4.bp_regres([-1,0,1],y4[1])\n",
        "    MSE += mln4.bp_regres([0,0,0],y4[2])\n",
        "    MSE += mln4.bp_regres([1,1,0],y4[3])\n",
        "    MSE += mln4.bp_regres([-1,-1,-1],y4[4])\n",
        "    MSE += mln4.bp_regres([-1,1,-1],y4[5])\n",
        "    MSE = MSE / 6\n",
        "    if(i%200 == 0):\n",
        "        print ('MSE=',MSE)\n",
        "mln4.printWeights()\n",
        "\n",
        "y4=[]\n",
        "y4.append(mln4.run([2,1,0])[0])\n",
        "y4.append(mln4.run([-1,0,1])[0])\n",
        "y4.append(mln4.run([0,0,0])[0])\n",
        "y4.append(mln4.run([1,1,0])[0])\n",
        "y4.append(mln4.run([-1,-1,-1])[0])\n",
        "y4.append(mln4.run([-1,1,-1])[0])\n",
        "display ('predicted values:',y4)\n",
        "print ()"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Layer 0 is the Input Layer\n",
            "Layer 1 Neuron 0 : [ 0  1 -2  1] sigmoid\n",
            "Layer 1 Neuron 1 : [ 1 -2  0  1] sigmoid\n",
            "Layer 2 Neuron 0 : [-1  2  3] linear\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'original values:'"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[3.5813200792821274,\n",
              " 3.731058578630005,\n",
              " 3.731058578630005,\n",
              " 3.119202922022118,\n",
              " 3.880797077977882,\n",
              " 2.2563920540063265]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "MSE= 16.716674234626698\n",
            "MSE= 0.6310297986858845\n",
            "MSE= 1.478703670208817\n",
            "MSE= 2.103572521455943\n",
            "MSE= 1.9332067650968952\n",
            "\n",
            "Layer 0 is the Input Layer\n",
            "Layer 1 Neuron 0 : [ 251.10660263 -501.13392304  252.97682973   -6.20030076] sigmoid\n",
            "Layer 1 Neuron 1 : [ 475.24547825 -947.61015604  477.7836324    -6.74983559] sigmoid\n",
            "Layer 2 Neuron 0 : [2.95371798 7.9291997  2.79979996] linear\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: RuntimeWarning: overflow encountered in exp\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'predicted values:'"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[2.979492921129191,\n",
              " 2.953990563729689,\n",
              " 2.8150551953706873,\n",
              " 2.7997999619712557,\n",
              " 2.800154883354388,\n",
              " 2.7997999619712557]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQ6f38VkOng4"
      },
      "source": [
        "# Example 5 -- various, bp_regres"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTgRMD9GOoF_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 936
        },
        "outputId": "34ebb07e-238e-449e-e181-940bdc54412b"
      },
      "source": [
        "mln4 = MultiLayerNeuron(layers=[3,2,1,1]) # generating MLN with random weights\n",
        "mln4.set_activ('relu')\n",
        "mln4.network[2][0].set_activ('sigmoid') # changing specific activ func\n",
        "mln4.set_output_activ('linear')\n",
        "mln4.set_weights([[[0,1,-2,1],[1,-2,0,1]],[[1,0,1]],[[-1,2]]]) # setting weights\n",
        "mln4.printWeights()\n",
        "\n",
        "y4=[] # generating output values\n",
        "y4.append(mln4.run([2,1,0])[0])\n",
        "y4.append(mln4.run([-1,0,1])[0])\n",
        "y4.append(mln4.run([0,0,0])[0])\n",
        "y4.append(mln4.run([1,1,0])[0])\n",
        "y4.append(mln4.run([-1,-1,-1])[0])\n",
        "y4.append(mln4.run([-1,1,-1])[0])\n",
        "display ('original values:',y4)\n",
        "print ()\n",
        "\n",
        "# training model and predicting values\n",
        "mln4 = MultiLayerNeuron(layers=[3,2,1,1], eta=0.3) # generating MLN with random weights\n",
        "mln4.set_activ('relu')\n",
        "mln4.network[2][0].set_activ('sigmoid') # changing specific activ func\n",
        "mln4.set_output_activ('linear')\n",
        "\n",
        "for i in range(4000):\n",
        "    MSE = 0.0\n",
        "    MSE += mln4.bp_regres([2,1,0],y4[0])\n",
        "    MSE += mln4.bp_regres([-1,0,1],y4[1])\n",
        "    MSE += mln4.bp_regres([0,0,0],y4[2])\n",
        "    MSE += mln4.bp_regres([1,1,0],y4[3])\n",
        "    MSE += mln4.bp_regres([-1,-1,-1],y4[4])\n",
        "    MSE += mln4.bp_regres([-1,1,-1],y4[5])\n",
        "    MSE = MSE / 6\n",
        "    if(i%200 == 0):\n",
        "        print ('MSE', i, '=',MSE)\n",
        "mln4.printWeights()\n",
        "\n",
        "y4=[]\n",
        "y4.append(mln4.run([2,1,0])[0])\n",
        "y4.append(mln4.run([-1,0,1])[0])\n",
        "y4.append(mln4.run([0,0,0])[0])\n",
        "y4.append(mln4.run([1,1,0])[0])\n",
        "y4.append(mln4.run([-1,-1,-1])[0])\n",
        "y4.append(mln4.run([-1,1,-1])[0])\n",
        "display ('predicted values:',y4)\n",
        "print ()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Layer 0 is the Input Layer\n",
            "Layer 1 Neuron 0 : [ 0  1 -2  1] relu\n",
            "Layer 1 Neuron 1 : [ 1 -2  0  1] relu\n",
            "Layer 2 Neuron 0 : [1 0 1] sigmoid\n",
            "Layer 3 Neuron 0 : [-1  2] linear\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'original values:'"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1.0474258731775667,\n",
              " 1.2689414213699952,\n",
              " 1.1192029220221178,\n",
              " 1.0474258731775667,\n",
              " 1.0474258731775667,\n",
              " 1.0066928509242847]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "MSE 0 = 2.652662917230955\n",
            "MSE 200 = 0.04520465482612365\n",
            "MSE 400 = 0.04118409816905768\n",
            "MSE 600 = 0.04024060735659487\n",
            "MSE 800 = 0.039826959023904755\n",
            "MSE 1000 = 0.03967275092502534\n",
            "MSE 1200 = 0.0395450916538607\n",
            "MSE 1400 = 0.03944010017907626\n",
            "MSE 1600 = 0.03935402611072759\n",
            "MSE 1800 = 0.03928325163598307\n",
            "MSE 2000 = 0.039224683730955875\n",
            "MSE 2200 = 0.0391758368127386\n",
            "MSE 2400 = 0.039134764035660595\n",
            "MSE 2600 = 0.03909995179388238\n",
            "MSE 2800 = 0.03907022156100762\n",
            "MSE 3000 = 0.039044650481688224\n",
            "MSE 3200 = 0.03902251047217594\n",
            "MSE 3400 = 0.039003222443119184\n",
            "MSE 3600 = 0.03898632205735386\n",
            "MSE 3800 = 0.03897143405383046\n",
            "\n",
            "Layer 0 is the Input Layer\n",
            "Layer 1 Neuron 0 : [ 0.39221434  0.40762168 -0.57138933 -1.19245729] relu\n",
            "Layer 1 Neuron 1 : [-0.97153621  0.35941008 -0.99323592 -0.44718933] relu\n",
            "Layer 2 Neuron 0 : [-0.209094    1.16140419 -2.36877473] sigmoid\n",
            "Layer 3 Neuron 0 : [-0.21628877  1.10467613] linear\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'predicted values:'"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1.0861650590568244,\n",
              " 1.0861650590568244,\n",
              " 1.0861650590568244,\n",
              " 1.0861650590568244,\n",
              " 1.0475080834426886,\n",
              " 1.0067118223095244]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iig6wESsnxe"
      },
      "source": [
        "# Example 7 -- Regres class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6k1A-gflH4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "outputId": "02efc09b-ba20-4310-9e34-fc182100e72d"
      },
      "source": [
        "reg1=Regres(layers=[3,2,1,1], eta=0.3)\n",
        "reg1.set_weights([[[1.,1.,0.,0.],[0.,0.,0.,0.]],[[0.,0.,0.]],[[0.,0.]]])\n",
        "X=[\n",
        "[2,1,0],\n",
        "[-1,0,1],\n",
        "[0,0,0],\n",
        "[1,1,0],\n",
        "[-1,-1,-1],\n",
        "[-1,1,-1],\n",
        "]\n",
        "y=[1.0474258731775667,\n",
        " 1.2689414213699952,\n",
        " 1.1192029220221178,\n",
        " 1.0474258731775667,\n",
        " 1.0474258731775667,\n",
        " 1.0066928509242847]\n",
        "reg1.set_hidden_activ('relu')\n",
        "reg1.regres_network.network[2][0].set_activ('sigmoid') # changing specific activ func\n",
        "reg1.fit(X,y, epochs=10)\n",
        "reg1.printWeights()\n",
        "pred=reg1.predict(X)\n",
        "print (pred)\n",
        "print()\n",
        "# display ('weight_history',reg1.weight_history)\n",
        "display ('MSE',reg1.MSE_history)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Layer 0 is the Input Layer\n",
            "Layer 1 Neuron 0 : [ 9.99023284e-01  1.00152136e+00 -9.19439041e-04  2.95824808e-03] relu\n",
            "Layer 1 Neuron 1 : [0. 0. 0. 0.] relu\n",
            "Layer 2 Neuron 0 : [-0.0528578   0.         -0.00270726] sigmoid\n",
            "Layer 3 Neuron 0 : [0.40569153 0.81590977] linear\n",
            "\n",
            "[1.0024198942493239, 1.01848095600904, 1.0184650968999405, 1.0077510108992154, 1.01848095600904, 1.018446775675626]\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'MSE'"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[0.8936248829442258,\n",
              " 0.04857883327236249,\n",
              " 0.0481469881158581,\n",
              " 0.04777680393002976,\n",
              " 0.04744442311981101,\n",
              " 0.047145341800303116,\n",
              " 0.04687567299207188,\n",
              " 0.04663204485218531,\n",
              " 0.04641152086265987,\n",
              " 0.046211534780671255]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEYHHIWrkLfj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "913d7be7-4471-451a-8aee-4c87459e153c"
      },
      "source": [
        "help(print)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on built-in function print in module builtins:\n",
            "\n",
            "print(...)\n",
            "    print(value, ..., sep=' ', end='\\n', file=sys.stdout, flush=False)\n",
            "    \n",
            "    Prints the values to a stream, or to sys.stdout by default.\n",
            "    Optional keyword arguments:\n",
            "    file:  a file-like object (stream); defaults to the current sys.stdout.\n",
            "    sep:   string inserted between values, default a space.\n",
            "    end:   string appended after the last value, default a newline.\n",
            "    flush: whether to forcibly flush the stream.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0_dFIMLvjG9",
        "outputId": "194520cd-6787-448c-a154-b3d797b6fc28"
      },
      "source": [
        "# nuzhno podumat' kak vesa obratno perevesti. mozhet inverse_transform\n",
        "reg2=Regres_scale(layers=[3,2,1,1], eta=0.3)\n",
        "reg2.set_weights([[[1.,1.,0.,0.],[0.,0.,0.,0.]],[[0.,0.,0.]],[[0.,0.]]])\n",
        "X=[\n",
        "[2,1,0],\n",
        "[-1,0,1],\n",
        "[0,0,0],\n",
        "[1,1,0],\n",
        "[-1,-1,-1],\n",
        "[-1,1,-1],\n",
        "]\n",
        "y=[1.0474258731775667,\n",
        " 1.2689414213699952,\n",
        " 1.1192029220221178,\n",
        " 1.0474258731775667,\n",
        " 1.0474258731775667,\n",
        " 1.0066928509242847]\n",
        "reg2.set_hidden_activ('relu')\n",
        "reg2.regres_network.network[2][0].set_activ('sigmoid') # changing specific activ func\n",
        "reg2.fit(X,y,epochs=200)\n",
        "reg2.printWeights()\n",
        "pred=reg2.predict(X)\n",
        "pred"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Layer 0 is the Input Layer\n",
            "Layer 1 Neuron 0 : [ 0.90094016  1.08501405 -0.07498197  0.09504859] relu\n",
            "Layer 1 Neuron 1 : [0. 0. 0. 0.] relu\n",
            "Layer 2 Neuron 0 : [-0.17097451  0.         -0.24461117] sigmoid\n",
            "Layer 3 Neuron 0 : [0.34647447 0.87394367] linear\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9847645694327527,\n",
              " 1.0260980418625074,\n",
              " 1.0247126609442043,\n",
              " 0.9966822456678671,\n",
              " 1.0260980418625074,\n",
              " 1.0209521040416654]"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMQEsh7bFFe9"
      },
      "source": [
        "# Example 6 -- https://mmuratarat.github.io/2020-01-09/backpropagation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvAnY1Q1FF_L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0227ca1e-171a-4747-96a4-f26ca7700832"
      },
      "source": [
        "# generating output values\n",
        "mln6 = MultiLayerNeuron(layers=[5,3,1], eta=.5)\n",
        "mln6.set_activ('sigmoid')\n",
        "mln6.set_output_activ('linear')\n",
        "mln6.set_weights([[[.19,.33,.4,.51,.54,.1],\n",
        "                   [.55,.16,.35,.85,.49,.1],\n",
        "                   [.76,.97,.7,.85,.57,.1]],\n",
        "                  [[.1,.03,-.17,.1]]\n",
        "                  ]) # setting initial weights\n",
        "mln6.printWeights()\n",
        "\n",
        "# training\n",
        "for i in range(100):\n",
        "    MSE = 0.0\n",
        "    MSE += mln6.bp_regres([.5,.1,1,0,0],[0.1])\n",
        "    MSE += mln6.bp_regres([.3,.2,0,1,0],[.6])\n",
        "    MSE += mln6.bp_regres([.7,.9,0,0,1],[.4])\n",
        "    MSE += mln6.bp_regres([.8,.1,1,0,0],[.1])\n",
        "    MSE = MSE / 4\n",
        "    if(i%10 == 0):\n",
        "        print ('MSE', i, '=',MSE)\n",
        "\n",
        "mln6.printWeights()"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Layer 0 is the Input Layer\n",
            "Layer 1 Neuron 0 : [0.19 0.33 0.4  0.51 0.54 0.1 ] sigmoid\n",
            "Layer 1 Neuron 1 : [0.55 0.16 0.35 0.85 0.49 0.1 ] sigmoid\n",
            "Layer 1 Neuron 2 : [0.76 0.97 0.7  0.85 0.57 0.1 ] sigmoid\n",
            "Layer 2 Neuron 0 : [ 0.1   0.03 -0.17  0.1 ] linear\n",
            "\n",
            "MSE 0 = 3.097759865123268\n",
            "MSE 10 = 0.2948017967667316\n",
            "MSE 20 = 0.11235016703947856\n",
            "MSE 30 = 0.039031749833149484\n",
            "MSE 40 = 0.005346702764168406\n",
            "MSE 50 = 0.00047155150910413527\n",
            "MSE 60 = 9.822149422722454e-05\n",
            "MSE 70 = 6.0504726410544755e-05\n",
            "MSE 80 = 4.67746394940529e-05\n",
            "MSE 90 = 3.966114337742912e-05\n",
            "\n",
            "Layer 0 is the Input Layer\n",
            "Layer 1 Neuron 0 : [-0.92948745 -0.3432972  -0.4785581   0.21811547 -0.0456272  -1.65606983] sigmoid\n",
            "Layer 1 Neuron 1 : [-1.01311017 -0.23274925 -1.57166574  1.18384536  0.1929425  -1.78487787] sigmoid\n",
            "Layer 1 Neuron 2 : [-0.09277171 -0.3986799   1.19699659 -0.59778185 -0.68424799 -2.10503325] sigmoid\n",
            "Layer 2 Neuron 0 : [ 0.25752661  0.97942477 -1.06640139  0.35525422] linear\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhdtW0Cjc7Fi"
      },
      "source": [
        "# Example 8 -- Relu check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eWXM7kbc6gn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "e843d809-9890-4194-a884-042a64a23d0f"
      },
      "source": [
        "reg2=Regres(layers=[1,1], eta=0.1)\n",
        "X=[[0.],[1.],[2.],[3.],[4.],[5.]]\n",
        "y=[0.,1.,2.,3.,4.,5.]\n",
        "reg2.printWeights()\n",
        "\n",
        "reg2.set_hidden_activ('linear')\n",
        "reg2.fit(X,y,epochs=5)\n",
        "reg2.printWeights()\n",
        "pred=reg2.predict(X)\n",
        "print (pred)\n",
        "print()\n",
        "display ('weight_history',reg2.weight_history)\n",
        "display ('MSE',reg2.MSE_history)"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Layer 0 is the Input Layer\n",
            "Layer 1 Neuron 0 : [-0.98341389 -0.65431364] linear\n",
            "\n",
            "\n",
            "Layer 0 is the Input Layer\n",
            "Layer 1 Neuron 0 : [1.00929573 0.01642246] linear\n",
            "\n",
            "[0.01642246285429991, 1.025718196545412, 2.035013930236524, 3.044309663927636, 4.053605397618749, 5.062901131309861]\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'weight_history'"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[[array([1.00929573, 0.01642246])],\n",
              " [array([1.00929573, 0.01642246])],\n",
              " [array([1.00929573, 0.01642246])],\n",
              " [array([1.00929573, 0.01642246])],\n",
              " [array([1.00929573, 0.01642246])]]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'MSE'"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[10.791498637420688,\n",
              " 1.5199521179822308,\n",
              " 0.2277264205291422,\n",
              " 0.03411905019472734,\n",
              " 0.005111877591916453]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEwuMi2DkFWq"
      },
      "source": [
        "# Example 9 -- mrelu check. working"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ay2oPnEzpHR3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 899
        },
        "outputId": "85462340-6ca3-4af6-dc08-72451b42c1cd"
      },
      "source": [
        "mln4 = MultiLayerNeuron(layers=[1,2,1]) # generating MLN with random weights\n",
        "mln4.set_activ('mrelu', param=0.1)\n",
        "# mln4.set_activ('relu')\n",
        "mln4.set_output_activ('linear')\n",
        "mln4.set_weights([[[-1.1,1.74],[3.35,-6.44]],[[-1.41,2.05,2.2]]]) # setting weights\n",
        "mln4.printWeights()\n",
        "\n",
        "y4=[] # generating output values\n",
        "y4.append(mln4.run([0])[0])\n",
        "y4.append(mln4.run([1])[0])\n",
        "y4.append(mln4.run([2])[0])\n",
        "y4.append(mln4.run([3])[0])\n",
        "y4.append(mln4.run([4])[0])\n",
        "y4.append(mln4.run([5])[0])\n",
        "display ('original values:',y4)\n",
        "print ()\n",
        "\n",
        "# training model and predicting values\n",
        "mln4 = MultiLayerNeuron(layers=[1,2,1], eta=0.005) # generating MLN with random weights\n",
        "mln4.set_activ('mrelu', param=0.1)\n",
        "# mln4.set_activ('relu')\n",
        "mln4.set_output_activ('linear')\n",
        "\n",
        "for i in range(4000):\n",
        "    MSE = 0.0\n",
        "    MSE += mln4.bp_regres([0],y4[0])\n",
        "    MSE += mln4.bp_regres([1],y4[1])\n",
        "    MSE += mln4.bp_regres([2],y4[2])\n",
        "    MSE += mln4.bp_regres([3],y4[3])\n",
        "    MSE += mln4.bp_regres([4],y4[4])\n",
        "    MSE += mln4.bp_regres([5],y4[5])\n",
        "    MSE = MSE / 6\n",
        "    if(i%200 == 0):\n",
        "        print ('MSE', i, '=',MSE)\n",
        "mln4.printWeights()\n",
        "\n",
        "y4=[]\n",
        "y4.append(mln4.run([0])[0])\n",
        "y4.append(mln4.run([1])[0])\n",
        "y4.append(mln4.run([2])[0])\n",
        "y4.append(mln4.run([3])[0])\n",
        "y4.append(mln4.run([4])[0])\n",
        "y4.append(mln4.run([5])[0])\n",
        "display ('predicted values:',y4)\n",
        "print ()"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Layer 0 is the Input Layer\n",
            "Layer 1 Neuron 0 : [-1.1   1.74] mrelu\n",
            "Layer 1 Neuron 1 : [ 3.35 -6.44] mrelu\n",
            "Layer 2 Neuron 0 : [-1.41  2.05  2.2 ] linear\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'original values:'"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[-1.5735999999999999,\n",
              " 0.6641500000000005,\n",
              " 2.7978599999999996,\n",
              " 9.82046,\n",
              " 16.843059999999998,\n",
              " 23.865659999999995]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "MSE 0 = 212.9818742647429\n",
            "MSE 200 = 1.95241717702793\n",
            "MSE 400 = 0.5487042459412064\n",
            "MSE 600 = 0.1897231055460981\n",
            "MSE 800 = 0.0932086194229352\n",
            "MSE 1000 = 0.05482719615365068\n",
            "MSE 1200 = 0.03288718988441663\n",
            "MSE 1400 = 0.02071105022734419\n",
            "MSE 1600 = 0.014510680382621393\n",
            "MSE 1800 = 0.010049610090113318\n",
            "MSE 2000 = 4.648542363502512\n",
            "MSE 2200 = 9.412987763956323\n",
            "MSE 2400 = 0.08257332918805783\n",
            "MSE 2600 = 0.019762614060483637\n",
            "MSE 2800 = 0.008819827891358297\n",
            "MSE 3000 = 0.004476111666594595\n",
            "MSE 3200 = 0.0023630850374690717\n",
            "MSE 3400 = 0.0012926690073169931\n",
            "MSE 3600 = 0.001291660220896314\n",
            "MSE 3800 = 0.0012916379057849548\n",
            "\n",
            "Layer 0 is the Input Layer\n",
            "Layer 1 Neuron 0 : [1.46716344e+00 5.68918381e-05] mrelu\n",
            "Layer 1 Neuron 1 : [ 3.05458588 -6.11869068] mrelu\n",
            "Layer 2 Neuron 0 : [ 1.12235938  1.75994936 -0.47882522] linear\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'predicted values:'"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[-1.5556199395472112,\n",
              " 0.62865636406093,\n",
              " 2.812932667669071,\n",
              " 9.820456263860041,\n",
              " 16.843057386158755,\n",
              " 23.865658508457464]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8pAh-iAkiJw",
        "outputId": "ee877dba-e887-417b-d63d-fd46ffeb8002",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "source": [
        "reg2=Regres(layers=[1,2,1], eta=0.0001)\n",
        "X=[[1],[2],[3],[4],[5]]\n",
        "y=[1.,4.,9.,16.,25.]\n",
        "# reg2.printWeights()\n",
        "\n",
        "reg2.set_hidden_activ('mrelu', param=0.1)\n",
        "reg2.fit(X,y,epochs=500)\n",
        "reg2.printWeights()\n",
        "pred=reg2.predict(X)\n",
        "print (pred)\n",
        "print()\n",
        "# display ('weight_history',reg2.weight_history)\n",
        "display ('MSE',np.array(reg2.MSE_history).min())"
      ],
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Layer 0 is the Input Layer\n",
            "Layer 1 Neuron 0 : [-0.32341138  0.76459193] mrelu\n",
            "Layer 1 Neuron 1 : [-0.25507667  0.04429681] mrelu\n",
            "Layer 2 Neuron 0 : [-0.21562986  0.62444639  4.34405303] linear\n",
            "\n",
            "[4.248921328482143, 4.318658478632218, 4.344053029757812, 4.344053029757812, 4.344053029757812]\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'MSE'"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "476.1662302367531"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}